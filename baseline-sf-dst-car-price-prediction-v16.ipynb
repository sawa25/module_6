{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029718,
     "end_time": "2020-10-26T12:46:41.276296",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.246578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Прогнозирование стоимости автомобиля по характеристикам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install catboost\n",
    "# %pip install sklearn\n",
    "# %pip install tqdm\n",
    "# %pip install phik\n",
    "# %pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n",
    "# %pip install seaborn\n",
    "# %pip install pandas-profiling[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:41.400302Z",
     "iopub.status.busy": "2020-10-26T12:46:41.399317Z",
     "iopub.status.idle": "2020-10-26T12:46:42.581426Z",
     "shell.execute_reply": "2020-10-26T12:46:42.580431Z"
    },
    "papermill": {
     "duration": 1.219772,
     "end_time": "2020-10-26T12:46:42.581597",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.361825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python       : 3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]\n",
      "Numpy        : 1.22.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42\n",
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "# %pip freeze > requirements.txt\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))\n",
    "VERSION    = 2\n",
    "DIR_TRAIN  = './input/parsing-all-moscow-auto-ru-09-09-2020/' # подключил к ноутбуку внешний датасет\n",
    "DIR_TEST   = './input/sf-dst-car-price-prediction/'\n",
    "VAL_SIZE   = 0.20   # 20%    \n",
    "\n",
    "# train = pd.read_csv(DIR_TRAIN+'all_auto_ru_09_09_2020.csv') # датасет для обучения модели\n",
    "test = pd.read_csv(DIR_TEST+'test.csv')\n",
    "sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\n",
    "train_my = pd.read_csv('dftrain.csv') # мой датасет для обучения модели\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip uninstall pandas-profiling\n",
    "# %pip install pandas-profiling[notebook,html]\n",
    "# %pip install ruamel-yaml\n",
    "\n",
    "#использование профилировщика пандас для изучения тестового датасета\n",
    "# from pandas_profiling import ProfileReport\n",
    "# profile = ProfileReport(test, title=\"Pandas Profiling Report\")\n",
    "# profile.to_file(\"your_report.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033402,
     "end_time": "2020-10-26T12:47:02.866506",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.833104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.025049Z",
     "iopub.status.busy": "2020-10-26T12:47:03.024167Z",
     "iopub.status.idle": "2020-10-26T12:47:03.134429Z",
     "shell.execute_reply": "2020-10-26T12:47:03.133689Z"
    },
    "papermill": {
     "duration": 0.156124,
     "end_time": "2020-10-26T12:47:03.134605",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.978481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train.dropna(subset=['productionDate','mileage'], inplace=True)\n",
    "# train.dropna(subset=['price'], inplace=True)\n",
    "# # для baseline просто возьму пару схожих признаков без полной обработки\n",
    "# columns = ['bodyType', 'brand', 'productionDate', 'engineDisplacement', 'mileage']\n",
    "\n",
    "# df_train = train[columns]\n",
    "# df_test = test[columns]\n",
    "# y = train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#из-за нехватки времени некоторые признаки в тренировочной базе являются неполными\n",
    "# адаптировать тестовый датасет, чтобы там не было отсутствующих значений для  таких признаков:\n",
    "mycolors=['чёрный', 'белый', 'серый', 'синий', 'серебристый','красный']\n",
    "test['color']=test['color'].apply(lambda x: x if (x in mycolors) else 'другой цвет')\n",
    "test['fuelType']=test['fuelType'].apply(lambda x: x if (x in ['бензин','дизель','гибрид']) else 'другое топливо')\n",
    "\n",
    "train_my['numberOfDoors']=train_my['numberOfDoors'].apply(lambda x: int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'complectation_dict','equipment_dict','model_info','super_gen',\n",
    "columns_my=['bodyType', 'brand', 'color', \n",
    "        'engineDisplacement', 'enginePower', \n",
    "       'fuelType',  'mileage', 'modelDate',  'model_name',\n",
    "       'name', 'numberOfDoors',  \n",
    "       'productionDate', 'sell_id',  'vehicleConfiguration',\n",
    "       'vehicleTransmission', 'vendor', 'Владельцы',  'ПТС',\n",
    "       'Привод', 'Руль']\n",
    "# columns_my = ['brand', 'color','bodyType' , #'productionDate', 'engineDisplacement', 'mileage',\n",
    "#        'fuelType'#,'modelDate'\n",
    "# ]\n",
    "\n",
    "# , 'complectation_dict'\n",
    "# , 'equipment_dict',\n",
    "# 'mileage',\n",
    "#  'model_info',\n",
    "# 'fuelType',\n",
    "# 'parsing_unixtime',\n",
    "# 'sell_id',\n",
    "# 'super_gen','modelDate','productionDate', \n",
    "cat_features_ids=['bodyType', 'brand', 'color',\n",
    "        'engineDisplacement', 'enginePower',\n",
    "           'model_name','name','fuelType',\n",
    "        'numberOfDoors',  \n",
    "         'vehicleConfiguration',\n",
    "       'vehicleTransmission', 'vendor', 'Владельцы',  'ПТС',\n",
    "       'Привод', 'Руль']\n",
    "\n",
    "# обновить признаки категорий в соответствии с выбранными столбцами из датасета\n",
    "# (при итеративном отключении и включении разных столбцов в тренировочные признаки при попытке выяснить, какой столбец рушит моментально catboost)\n",
    "cat_features_ids=list(set(columns_my).intersection(set(cat_features_ids)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_4800/1997197722.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_my['sample'] = 1 # помечаем где у нас трейн\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_4800/1997197722.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['sample'] = 0 # помечаем где у нас тест\n"
     ]
    }
   ],
   "source": [
    "# выбрать столбцы для передачи в регрессоры\n",
    "df_train_my = train_my[columns_my]\n",
    "y = train_my['price']\n",
    "df_test = test[columns_my]\n",
    "\n",
    "df_train_my['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "data_my = df_test.append(df_train_my, sort=False).reset_index(drop=True) # объединяем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035737,
     "end_time": "2020-10-26T12:47:03.826552",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.790815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:03.90948Z",
     "iopub.status.busy": "2020-10-26T12:47:03.908518Z",
     "iopub.status.idle": "2020-10-26T12:47:03.923409Z",
     "shell.execute_reply": "2020-10-26T12:47:03.922602Z"
    },
    "papermill": {
     "duration": 0.059208,
     "end_time": "2020-10-26T12:47:03.923564",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.864356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'engineDisplacement', 'bodyType', 'model_name', 'brand', 'productionDate', 'modelDate', 'color', 'vehicleConfiguration', 'vendor', 'enginePower', 'Владельцы', 'mileage', 'Привод', 'vehicleTransmission', 'ПТС', 'Руль', 'sample', 'fuelType', 'name', 'numberOfDoors', 'sell_id'}\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Создадим \"наивную\" модель \n",
    "Эта модель будет предсказывать среднюю цену по модели двигателя (engineDisplacement). \n",
    "C ней будем сравнивать другие модели.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier, ExtraTreesClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats.distributions import randint\n",
    "\n",
    "class AlgRegressor:\n",
    "    algs={}\n",
    "    cat_features=None,None\n",
    "    isFit=False\n",
    "    lastbestparams=None\n",
    "    rf_random=None\n",
    "    def __init__(self,data_my,y,cat_features=None) -> None:\n",
    "        self.y=y\n",
    "        if cat_features is None:\n",
    "            pass\n",
    "        else:\n",
    "            self.cat_features=cat_features\n",
    "            for colum in cat_features:\n",
    "                data_my[colum] = data_my[colum].astype('category').cat.codes\n",
    "        scaler = StandardScaler()\n",
    "        sample=set(data_my.columns).difference('sample')\n",
    "        data_my_ = pd.DataFrame(data=scaler.fit_transform(data_my), columns=sample)\n",
    "        data_my_['sample']=data_my['sample']\n",
    "        # приготовить скалированные данные и\n",
    "        self.X_ = data_my_.query('sample == 1').drop(['sample'], axis=1)\n",
    "        self.X_sub_ = data_my_.query('sample == 0').drop(['sample'], axis=1)\n",
    "        # и неизменные\n",
    "        self.X = data_my.query('sample == 1').drop(['sample'], axis=1)\n",
    "        self.X_sub = data_my.query('sample == 0').drop(['sample'], axis=1)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)       \n",
    "        self.X_train_, self.X_test_, self.y_train_, self.y_test_ = train_test_split(self.X_, self.y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)       \n",
    "        super().__init__()\n",
    "\n",
    "    def addalg(self,_name_,alg):\n",
    "        self.algs[_name_]=alg\n",
    "        print(_name_)\n",
    "    def fitpredict(self,algname,isScaler=False,isX_sub=False):\n",
    "        # if not (X_sub is None) and not self.isFit: raise Exception('не было обучения')\n",
    "        alg=self.algs[algname]\n",
    "        if isX_sub: \n",
    "            if isScaler:\n",
    "                return alg.predict(self.X_sub_)\n",
    "            else:\n",
    "                return alg.predict(self.X_sub)\n",
    "        else:\n",
    "            if isScaler:\n",
    "                alg.fit(self.X_train_, self.y_train_)\n",
    "                return alg.predict(self.X_test_)\n",
    "            else:\n",
    "                alg.fit(self.X_train, self.y_train)\n",
    "                # self.isFit=True\n",
    "                return alg.predict(self.X_test)\n",
    "    def setp(self,algname,**params):\n",
    "        self.algs[algname].set_params(**params)\n",
    "        for qq in params:\n",
    "            print(str(self.algs[algname].get_params()[qq]))\n",
    "    def fullname(algname):\n",
    "        return str(alg.algs[algname]).split(\".\")[-1].rstrip(\"'>\")\n",
    "\n",
    "    def SearchCV(self,algname,isScaler=False,rf_random=None):\n",
    "        if (self.algs[algname] is None): raise Exception('не инициализирован регрессор')\n",
    "        if rf_random is None:\n",
    "            n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "            max_features = ['auto', 'sqrt']\n",
    "            max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "            max_depth.append(None)\n",
    "            min_samples_split = [2, 5, 10]\n",
    "            min_samples_leaf = [1, 2, 4]\n",
    "            bootstrap = [True, False]\n",
    "            random_grid = {'n_estimators': n_estimators,\n",
    "                        'max_features': max_features,\n",
    "                        'max_depth': max_depth,\n",
    "                        'min_samples_split': min_samples_split,\n",
    "                        'min_samples_leaf': min_samples_leaf,\n",
    "                        'bootstrap': bootstrap}\n",
    "            self.searchCV= RandomizedSearchCV(estimator=self.algs[algname], param_distributions=random_grid, n_iter=100, \n",
    "                                cv=3, verbose=2, random_state=RANDOM_SEED, n_jobs=-1)\n",
    "        else: self.searchCV=rf_random\n",
    "        \n",
    "        \n",
    "        if isScaler:\n",
    "            self.searchCV.fit(self.X_train, self.y_train)                    \n",
    "        else:\n",
    "            self.searchCV.fit(self.X_train_, self.y_train_)  \n",
    "        self.lastbestparams=rf_random.best_params_\n",
    "        self.algs[algname].set_params(**self.lastbestparams)\n",
    "    # здесь передаются ndarrays , а не dataframe\n",
    "    def compute_meta_feature(self,clf, X_train, X_test, y_train, cv):\n",
    "        \"\"\"\n",
    "        Computes meta-features using the regressor.\n",
    "        :arg clf: scikit-learn regressor\n",
    "        :args X_train, y_train: training set\n",
    "        :arg X_test: testing set\n",
    "        :arg cv: cross-validation folding\n",
    "        \"\"\"\n",
    "        X_meta_train = np.zeros_like(y_train, dtype=np.float32)\n",
    "        for train_fold_index, predict_fold_index in cv.split(X_train):\n",
    "            X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "            y_fold_train = y_train[train_fold_index]\n",
    "            \n",
    "            folded_clf = clone(clf)\n",
    "            folded_clf.fit(X_fold_train, y_fold_train)\n",
    "            X_meta_train[predict_fold_index] = folded_clf.predict(X_fold_predict)\n",
    "        \n",
    "        meta_clf = clone(clf)\n",
    "        meta_clf.fit(X_train, y_train)\n",
    "        \n",
    "        X_meta_test = meta_clf.predict(X_test)\n",
    "        \n",
    "        return X_meta_train, X_meta_test\n",
    "    def generate_meta_features(self,nregressors,  cv,isScaler=False):\n",
    "        \"\"\"\n",
    "        Generates metafeatures using a list of regressors.\n",
    "        :arg regressors: list of scikit-learn regressors\n",
    "        :args X_train, y_train: training set\n",
    "        :arg X_test: testing set\n",
    "        :arg cv: cross-validation folding\n",
    "        \"\"\"\n",
    "        if isScaler:\n",
    "            X_train, X_test, y_train=alg.X_train_.to_numpy(), alg.X_test_.to_numpy(), alg.y_train_.to_numpy()\n",
    "        else:\n",
    "            X_train, X_test, y_train=alg.X_train.to_numpy(), alg.X_test.to_numpy(), alg.y_train_.to_numpy()\n",
    "        regressors=[alg.algs[i] for i in nregressors]\n",
    "        features = [\n",
    "            compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
    "            for clf in tqdm(regressors)\n",
    "        ]\n",
    "        \n",
    "        tr = np.vstack([\n",
    "            features_train for features_train, features_test in features\n",
    "        ]).T\n",
    "\n",
    "        tst = np.vstack([\n",
    "            features_test for features_train, features_test in features\n",
    "        ]).T\n",
    "        if isScaler:\n",
    "            self.stacked_features_train_=tr\n",
    "            self.stacked_features_test_= tst\n",
    "        else:\n",
    "            self.stacked_features_train=tr\n",
    "            self.stacked_features_test=tst\n",
    "        \n",
    "        return tr, tst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTR\n",
      "RFR\n",
      "Ada\n",
      "GBoo\n"
     ]
    }
   ],
   "source": [
    "alg=AlgRegressor(data_my,y,cat_features_ids)\n",
    "# добавление разных регрессоров\n",
    "alg.addalg('LR',LinearRegression())\n",
    "alg.addalg('DTR',DecisionTreeRegressor(random_state=RANDOM_SEED))\n",
    "alg.addalg('RFR',RandomForestRegressor(random_state=RANDOM_SEED))\n",
    "alg.addalg('Ada',AdaBoostRegressor(random_state=RANDOM_SEED))\n",
    "alg.addalg('GBoo',GradientBoostingRegressor(learning_rate=0.1, n_estimators=100, \n",
    "                max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1, max_features=int(len(data_my.columns)/3), random_state=RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n"
     ]
    }
   ],
   "source": [
    "def predictionresult(algname): #проверка для выбранного алгоритма на немасштабированных и масштабированных признаках\n",
    "    predict= (alg.fitpredict(algname),alg.fitpredict(algname,isScaler=True))\n",
    "    print(\"Точность {}/(StandardScaler) по метрике MAPE,%: {:0.2f}/{:0.2f}\".format(alg.fullname(algname),\n",
    "    mean_absolute_percentage_error(alg.y_test_, predict[0])*100,\n",
    "    mean_absolute_percentage_error(alg.y_test, predict[1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность LinearRegression()/(StandardScaler) по метрике MAPE,%: 83.87/85.43\n"
     ]
    }
   ],
   "source": [
    "# линейная регрессия хуже остальных алгоритмов предсказывает\n",
    "predictionresult('LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность AdaBoostRegressor/(StandardScaler) по метрике MAPE,%: 439.98/436.39\n"
     ]
    }
   ],
   "source": [
    "predictionresult('Ada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность GradientBoostingRegressor(max_features=7, random_state=42, subsample=1/(StandardScaler) по метрике MAPE,%: 27.93/28.41\n"
     ]
    }
   ],
   "source": [
    "predictionresult('GBoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "10\n",
      "4\n",
      "sqrt\n",
      "20\n",
      "Точность GradientBoostingRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=4,\n",
      "                          min_samples_split=10, n_estimators=1200,\n",
      "                          random_state=42, subsample=1)/(StandardScaler) по метрике MAPE,%: 18.93/19.39\n"
     ]
    }
   ],
   "source": [
    "bparams={'n_estimators': 1200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20}\n",
    "alg.setp('GBoo',**bparams)\n",
    "predictionresult('GBoo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность DecisionTreeRegressor(max_depth=4, random_state=42)/(StandardScaler) по метрике MAPE,%: 45.57/45.57\n"
     ]
    }
   ],
   "source": [
    "predictionresult('DTR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность RandomForestRegressor(random_state=42)/(StandardScaler) по метрике MAPE,%: 18.93/19.08\n"
     ]
    }
   ],
   "source": [
    "predictionresult('RFR') #точность RandomForestRegressor по MAPE из коробки получилась выше, чем с подбором гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "10\n",
      "4\n",
      "sqrt\n",
      "20\n",
      "False\n",
      "Точность RandomForestRegressor(bootstrap=False, max_depth=20, max_features='sqrt',\n",
      "                      min_samples_leaf=4, min_samples_split=10,\n",
      "                      n_estimators=1200, random_state=42)/(StandardScaler) по метрике MAPE,%: 19.33/19.27\n"
     ]
    }
   ],
   "source": [
    "# всю ночь выполнялся перебор alg.SearchCV('RFR')\n",
    "# но лучших результатов не получилось\n",
    "# Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
    "# {'n_estimators': 1200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n",
    "bparams={'n_estimators': 1200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n",
    "alg.setp('RFR',**bparams)\n",
    "predictionresult('RFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23.20% при max_depth=14\n",
    "# быстрее на  порядок считает, чем RandomForestRegressor\n",
    "for depth in range(4,25):\n",
    "    alg.setp('DTR',max_depth=depth)\n",
    "    predict= alg.fitpredict('DTR',isScaler=True)\n",
    "    print(f\"Точность DecisionTreeRegressor по метрике MAPE: {(mape(alg.y_test_, predict))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22.99% при max_depth=14\n",
    "for depth in range(4,25):\n",
    "    alg.setp('DTR',max_depth=depth)\n",
    "    predict= alg.fitpredict('DTR')\n",
    "    print(f\"Точность DecisionTreeRegressor по метрике MAPE: {(mape(alg.y_test, predict))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Computes meta-features using the regressor.\n",
    "    :arg clf: scikit-learn regressor\n",
    "    :args X_train, y_train: training set\n",
    "    :arg X_test: testing set\n",
    "    :arg cv: cross-validation folding\n",
    "    \"\"\"\n",
    "    X_meta_train = np.zeros_like(y_train, dtype=np.float32)\n",
    "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
    "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "        y_fold_train = y_train[train_fold_index]\n",
    "        \n",
    "        folded_clf = clone(clf)\n",
    "        folded_clf.fit(X_fold_train, y_fold_train)\n",
    "        X_meta_train[predict_fold_index] = folded_clf.predict(X_fold_predict)\n",
    "    \n",
    "    meta_clf = clone(clf)\n",
    "    meta_clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_meta_test = meta_clf.predict(X_test)\n",
    "    \n",
    "    return X_meta_train, X_meta_test\n",
    "def generate_meta_features(regressors, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Generates metafeatures using a list of regressors.\n",
    "    :arg regressors: list of scikit-learn regressors\n",
    "    :args X_train, y_train: training set\n",
    "    :arg X_test: testing set\n",
    "    :arg cv: cross-validation folding\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
    "        for clf in tqdm(regressors)\n",
    "    ]\n",
    "    \n",
    "    stacked_features_train = np.vstack([\n",
    "        features_train for features_train, features_test in features\n",
    "    ]).T\n",
    "\n",
    "    stacked_features_test = np.vstack([\n",
    "        features_test for features_train, features_test in features\n",
    "    ]).T\n",
    "    \n",
    "    return stacked_features_train, stacked_features_test\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "def fitfit(clf, X_train, y_train, X_test,y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    print(\"Точность {}/(StandardScaler) по метрике MAPE,%: {:0.2f}/{:0.2f}\".format('стекинг',\n",
    "    mean_absolute_percentage_error(y_test, y_test_pred)*100,0))\n",
    "    return y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "nrgs=['DTR','LR','RFR','GBoo']\n",
    "rgs=[alg.algs[i] for i in nrgs]\n",
    "\n",
    "qq=[alg.algs['DTR'],\n",
    "    alg.algs['LR'],\n",
    "    alg.algs['RFR'],\n",
    "    alg.algs['GBoo']]\n",
    "print(rgs==qq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nalgs=['DTR','LR','RFR','GBoo']\n",
    "stacked_features_train_, stacked_features_test_ = alg.generate_meta_features(nalgs, cv,isScaler=True)    \n",
    "for Alg in nalgs:\n",
    "    clf = alg.algs[Alg]\n",
    "    clf.fit(stacked_features_train_, alg.y_train_)\n",
    "\n",
    "stacked_features_train, stacked_features_test = alg.generate_meta_features(nalgs, cv,isScaler=False)    \n",
    "\n",
    "y_test_pred=fitfit(clf, X_train=stacked_features_train,y_train=alg.y_train_, X_test=stacked_features_test,y_test=alg.y_test_)\n",
    "\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037164,
     "end_time": "2020-10-26T12:47:03.997616",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.960452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # Model 2 : CatBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035833,
     "end_time": "2020-10-26T12:47:04.149539",
     "exception": false,
     "start_time": "2020-10-26T12:47:04.113706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Traget\n",
    "Попробуем взять таргет в логорифм - это позволит уменьшить влияние выбросов на обучение модели (используем для этого np.log и np.exp).    \n",
    "В принциепе мы можем использовать любое приобразование на целевую переменную. Например деление на курс доллара, евро или гречки :) в дату сбора данных, смотрим дату парсинга в тесте в **parsing_unixtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попытки разобраться с признаком parse_unixtime\n",
    "# from datetime import datetime\n",
    "# def parseunix(x):\n",
    "#     ts = int(x)\n",
    "#     return datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "\n",
    "# df_=test.loc[:,['parsing_unixtime']] \n",
    "# df_['unixtime']=df_['parsing_unixtime'].apply(parseunix)\n",
    "\n",
    "# df_.sort_values(by='unixtime',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations = 5000,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE'],\n",
    "                          silent=True,\n",
    "                         )\n",
    "model.fit(X_train, np.log(y_train),\n",
    "         cat_features=cat_features_ids,\n",
    "         eval_set=(X_test, np.log(y_test)),\n",
    "         verbose_eval=20,\n",
    "         use_best_model=True,\n",
    "        #  plot=True\n",
    "         )\n",
    "\n",
    "model.save_model('catboost_single_model_2_baseline.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = np.exp(model.predict(X_test))\n",
    "predict_submission = np.exp(model.predict(X_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели по метрике MAPE: 19.33%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, predict_test))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим точность возросла до 15%, а что будет на ЛБ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.085876,
     "end_time": "2020-10-26T12:48:12.734207",
     "exception": false,
     "start_time": "2020-10-26T12:48:12.648331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:48:13.227584Z",
     "iopub.status.busy": "2020-10-26T12:48:13.226285Z",
     "iopub.status.idle": "2020-10-26T12:48:13.762529Z",
     "shell.execute_reply": "2020-10-26T12:48:13.763259Z"
    },
    "papermill": {
     "duration": 0.628302,
     "end_time": "2020-10-26T12:48:13.763488",
     "exception": false,
     "start_time": "2020-10-26T12:48:13.135186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34686 entries, 0 to 34685\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   sell_id  34686 non-null  int64  \n",
      " 1   price    34686 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 542.1 KB\n"
     ]
    }
   ],
   "source": [
    "sample_submission['price'] = predict_submission\n",
    "sample_submission.to_csv(f'submission_myds_v{VERSION}.csv', index=False)\n",
    "sample_submission.head(10)\n",
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.083769,
     "end_time": "2020-10-26T12:48:13.930562",
     "exception": false,
     "start_time": "2020-10-26T12:48:13.846793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "В итоге получили **MAPE 27%** на ЛБ!\n",
    "\n",
    "Большая разница в ошибке может указывать на то что тест и трейн имеют различия по выборке или то что данные в трейне могли уже устареть и их нужно обновлять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.087712,
     "end_time": "2020-10-26T12:48:14.104388",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.016676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What's next?\n",
    "Или что еще можно сделать, чтоб улучшить результат:\n",
    "\n",
    "* Спарсить свежие данные \n",
    "* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки\n",
    "* Сгенерировать новые признаки\n",
    "* Попробовать подобрать параметры модели\n",
    "* Попробовать другие алгоритмы и библиотеки ML\n",
    "* Сделать Ансамбль моделей, Blending, Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробный чек лист: https://docs.google.com/spreadsheets/d/1I_ErM3U0Cs7Rs1obyZbIEGtVn-H47pHNCi4xdDgUmXY/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.082055,
     "end_time": "2020-10-26T12:48:14.270602",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.188547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.08168,
     "end_time": "2020-10-26T12:48:14.435554",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.353874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.080788,
     "end_time": "2020-10-26T12:48:14.596978",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.51619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
