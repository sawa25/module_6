{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029718,
     "end_time": "2020-10-26T12:46:41.276296",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.246578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Прогнозирование стоимости автомобиля по характеристикам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install catboost\n",
    "# %pip install sklearn\n",
    "# %pip install tqdm\n",
    "# %pip install phik\n",
    "# %pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n",
    "# %pip install seaborn\n",
    "# %pip install pandas-profiling[notebook]\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:41.400302Z",
     "iopub.status.busy": "2020-10-26T12:46:41.399317Z",
     "iopub.status.idle": "2020-10-26T12:46:42.581426Z",
     "shell.execute_reply": "2020-10-26T12:46:42.580431Z"
    },
    "papermill": {
     "duration": 1.219772,
     "end_time": "2020-10-26T12:46:42.581597",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.361825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n",
      "Python       : 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n",
      "Numpy        : 1.20.3\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xg\n",
    "print(xgboost.__version__)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "#                               RandomForestClassifier, ExtraTreesClassifier)\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats.distributions import randint\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42\n",
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "# %pip freeze > requirements.txt\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))\n",
    "\n",
    "\n",
    "VERSION = 2\n",
    "\n",
    "DIR_TEST = './input/sf-dst-car-price-prediction/'\n",
    "VAL_SIZE = 0.20   # 20%\n",
    "\n",
    "test = pd.read_csv(DIR_TEST+'test.csv')\n",
    "sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\n",
    "train_my = pd.read_csv('dftrain.csv')  # мой датасет для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip uninstall pandas-profiling\n",
    "# %pip install pandas-profiling[notebook,html]\n",
    "# %pip install ruamel-yaml\n",
    "\n",
    "# использование профилировщика пандас для изучения тестового датасета\n",
    "\n",
    "\n",
    "# from pandas_profiling import ProfileReport\n",
    "# profile = ProfileReport(test, title=\"Pandas Profiling Report\")\n",
    "# profile.to_file(\"your_report.html\")\n",
    "# profile.to_file(\"your_trainreport.html\")\n",
    "\n",
    "\n",
    "# разведывательный анализ проведен по результатам работы профилировщика\n",
    "# на болшее времени не осталось\n",
    "# исключены ненужные признаки Таможня, Состояние,priceCurrency,image,\n",
    "#  а так же те, из которых на данном этапе не получится извлечь пользы,\n",
    "# такие как из котор car_url,description.\n",
    "\n",
    "# работа со словарями 'complectation_dict','equipment_dict','model_info','super_gen' тоже не проведена\n",
    "# признак Владение пришлось выбросить на этапе сбора тадасета, т.к. предполагалось времязатратным \n",
    "# найти нужные данные, и сформировать аналог записям, которые есть в test.csv (месяцы леты и годы в падежах)\n",
    "# большая часть времени ушла на сбор тренировочного датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033402,
     "end_time": "2020-10-26T12:47:02.866506",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.833104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# из-за нехватки времени некоторые признаки в тренировочной базе являются неполными\n",
    "# адаптировать тестовый датасет, чтобы там не было отсутствующих значений для  таких признаков:\n",
    "# не все цвета были сопоставлены с номерами, поэтому часть наименее употребимых цветов заменена на'другой цвет'\n",
    "mycolors = ['чёрный', 'белый', 'серый', 'синий', 'серебристый', 'красный']\n",
    "test['color'] = test['color'].apply(\n",
    "    lambda x: x if (x in mycolors) else 'другой цвет')\n",
    "# моделей с на газе или электричестве тоже в собранном датасете не оказалось\n",
    "test['fuelType'] = test['fuelType'].apply(lambda x: x if (\n",
    "    x in ['бензин', 'дизель', 'гибрид']) else 'другое топливо')\n",
    "\n",
    "# количество дверей у меня набралось числом float - перевести в int\n",
    "train_my['numberOfDoors'] = train_my['numberOfDoors'].apply(lambda x: int(x))\n",
    "\n",
    "# test.csv собран 20 октября 2020г 77,9241 RUB за 1 USD 91,3115 RUB за 1 EUR\n",
    "# мой датасет собран 17 января 2022г 75,7668 RUB за 1 USD 86,8894 RUB за 1 EUR\n",
    "# соотношение рубля, доллара и евро, судя по цене автомобиля  84.07руб/евро и 74.3руб/USD при курсе на 17 января 2022\n",
    "# (значит продажа в магазинах в пересчете на валюту чуть по меньшему курсу, чем центробанк)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsing_unixtime</th>\n",
       "      <th>unixtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1603226273</td>\n",
       "      <td>2020-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1603226277</td>\n",
       "      <td>2020-10-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parsing_unixtime    unixtime\n",
       "0        1603226273  2020-10-20\n",
       "1        1603226277  2020-10-20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# попытка учесть изменение курса валюты\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def parseunix(x):\n",
    "    ts = int(x)\n",
    "    return datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "\n",
    "df_ = test.loc[:, ['parsing_unixtime']]\n",
    "df_['unixtime'] = df_['parsing_unixtime'].apply(parseunix)\n",
    "\n",
    "df_.sort_values(by='unixtime', ascending=True)\n",
    "df_.iloc[:2]\n",
    "# test.csv собран 20 октября 2020г 77,9241 RUB за 1 USD 91,3115 RUB за 1 EUR\n",
    "# мой датасет собран 17 января 2022г 75,7668 RUB за 1 USD 86,8894 RUB за 1 EUR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88.34861105036977, 76.41553596034147)\n"
     ]
    }
   ],
   "source": [
    "# как отличается курс евро и доллара центробанка от магазинов, если вычислять по стоимости автомобиля в рублях и разных валютах\n",
    "# train_my['priceadaptEU']=train_my.apply(lambda x: x.price/x.priceEUR,axis=1)\n",
    "# train_my['priceadaptUS']=train_my.apply(lambda x: x.price/x.priceUSD,axis=1)\n",
    "\n",
    "now = (86.8894/84.07, 75.7668/74.3)\n",
    "# если соотношение курса для центробанка и магазинов было такое же, как сейчас,\n",
    "# то такой был курс валюты в магазинах при пересчете из валюты в рубли\n",
    "ago = (91.3115/now[0], 77.9241/now[1])\n",
    "print(ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>priceEUR</th>\n",
       "      <th>priceUSD</th>\n",
       "      <th>priceadapt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13444</th>\n",
       "      <td>1520000.0</td>\n",
       "      <td>18081.0</td>\n",
       "      <td>20459.0</td>\n",
       "      <td>1.580408e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15290</th>\n",
       "      <td>340000.0</td>\n",
       "      <td>4044.0</td>\n",
       "      <td>4577.0</td>\n",
       "      <td>3.535178e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10898</th>\n",
       "      <td>360000.0</td>\n",
       "      <td>4282.0</td>\n",
       "      <td>4845.0</td>\n",
       "      <td>3.742710e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11617</th>\n",
       "      <td>1870000.0</td>\n",
       "      <td>22243.0</td>\n",
       "      <td>25171.0</td>\n",
       "      <td>1.944297e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16379</th>\n",
       "      <td>2270000.0</td>\n",
       "      <td>27001.0</td>\n",
       "      <td>30555.0</td>\n",
       "      <td>2.360189e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  priceEUR  priceUSD    priceadapt\n",
       "13444  1520000.0   18081.0   20459.0  1.580408e+06\n",
       "15290   340000.0    4044.0    4577.0  3.535178e+05\n",
       "10898   360000.0    4282.0    4845.0  3.742710e+05\n",
       "11617  1870000.0   22243.0   25171.0  1.944297e+06\n",
       "16379  2270000.0   27001.0   30555.0  2.360189e+06"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# адаптировать цену в рублях пересчетом из валюты\n",
    "train_my['priceadapt'] = train_my.apply(lambda x: np.mean(\n",
    "    [ago[0]*x.priceEUR, ago[1]*x.priceUSD]), axis=1)\n",
    "train_my[['price', 'priceEUR', 'priceUSD', 'priceadapt']].sample(5)\n",
    "# priceadapt - адаптированная цена пересчетом курса валют,\n",
    "# однако на кагле рейтинг не изменился ни на копейку для двух результатов - с пересчетом цены и без пересчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# с этими признаками я не успеваю поработать\n",
    "# 'complectation_dict','equipment_dict','model_info','super_gen',\n",
    "# придется их пока выкинуть из базы\n",
    "\n",
    "\n",
    "# оставшиеся признаки, по которым буду предсказывать цену\n",
    "columns_my = ['bodyType', 'brand', 'color',\n",
    "              'engineDisplacement', 'enginePower',\n",
    "              'fuelType',  'mileage', 'modelDate',  'model_name',\n",
    "              'name', 'numberOfDoors',\n",
    "              'productionDate', 'sell_id',  'vehicleConfiguration',\n",
    "              'vehicleTransmission', 'vendor', 'Владельцы',  'ПТС',\n",
    "              'Привод', 'Руль']\n",
    "\n",
    "\n",
    "# это категорийные признаки\n",
    "cat_features_ids = ['bodyType', 'brand', 'color',\n",
    "                    'engineDisplacement', 'enginePower',\n",
    "                    'model_name', 'name', 'fuelType',\n",
    "                    'numberOfDoors',\n",
    "                    'vehicleConfiguration',\n",
    "                    'vehicleTransmission', 'vendor', 'Владельцы',  'ПТС',\n",
    "                    'Привод', 'Руль']\n",
    "\n",
    "# обновить признаки категорий в соответствии с выбранными столбцами из датасета\n",
    "# (при итеративном отключении и включении разных столбцов в тренировочные признаки при попытке выяснить, какой столбец рушит моментально catboost)\n",
    "cat_features_ids = list(set(columns_my).intersection(set(cat_features_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_17804/1121124924.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_my['sample'] = 1  # помечаем где у нас трейн\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_17804/1121124924.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['sample'] = 0  # помечаем где у нас тест\n"
     ]
    }
   ],
   "source": [
    "# выбрать столбцы для передачи в регрессоры\n",
    "df_train_my = train_my[columns_my]\n",
    "y = train_my['price']\n",
    "df_test = test[columns_my]\n",
    "\n",
    "df_train_my['sample'] = 1  # помечаем где у нас трейн\n",
    "df_test['sample'] = 0  # помечаем где у нас тест\n",
    "data_my = df_test.append(df_train_my, sort=False).reset_index(\n",
    "    drop=True)  # объединяем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Перепробование разных регрессоров, ансамблей и стекинга\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс -обертка для управления регрессорами\n",
    "class AlgRegressor:\n",
    "    # словарь регрессоров по короткому имени;\n",
    "    # везде к именам добавляется нижнее подчеркивание для данных, обработанных StandardScaler или при их использовании\n",
    "    # копия каждого регрессора для масштабированных данных хранится по такому же имени с нижним подчеркиванием\n",
    "    algs = {}\n",
    "    # гиперпараметры только что выполненного поиска  и последнего переданного регрессора\n",
    "    lastbestparams = None\n",
    "    rf_random = None  # поисковик гиперпараметров\n",
    "\n",
    "    def __init__(self, data_my, y, cat_features=None) -> None:\n",
    "        self.y = y\n",
    "        if cat_features is None:\n",
    "            pass\n",
    "        else:  # перевести признаки из категорийных столбцов в числа\n",
    "            self.cat_features = cat_features\n",
    "            for colum in cat_features:\n",
    "                data_my[colum] = data_my[colum].astype('category').cat.codes\n",
    "        scaler = StandardScaler()\n",
    "        sample = set(data_my.columns).difference('sample')\n",
    "        data_my_ = pd.DataFrame(\n",
    "            data=scaler.fit_transform(data_my), columns=sample)\n",
    "        data_my_['sample'] = data_my['sample']\n",
    "        # приготовить масштабированные данные и\n",
    "        self.X_ = data_my_.query('sample == 1').drop(['sample'], axis=1)\n",
    "        self.X_sub_ = data_my_.query('sample == 0').drop(['sample'], axis=1)\n",
    "        # и неизменные\n",
    "        self.X = data_my.query('sample == 1').drop(['sample'], axis=1)\n",
    "        self.X_sub = data_my.query('sample == 0').drop(['sample'], axis=1)\n",
    "        # приготовить тренировочный и тестовый наборы для масштабированныхъ и нет признаков\n",
    "        self.X_train_, self.X_test_, self.y_train_, self.y_test_ = train_test_split(\n",
    "            self.X_, self.y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)\n",
    "        super().__init__()\n",
    "\n",
    "    def addalg(self, algname, alg):  # добавить в словарь очередной регрессор\n",
    "        self.algs[algname] = alg\n",
    "        # продублировать алгоритм для масштабироваанных признаков\n",
    "        self.algs[algname+\"_\"] = clone(alg)\n",
    "        print(algname)\n",
    "\n",
    "    # вызвать fit и predict для регрессора в словаре\n",
    "    def fitpredict(self, algname, isScaler=False, isX_sub=False):\n",
    "\n",
    "        # isScaler-работать с масштабированными признаками\n",
    "        # isX_sub-делать предикт для рабочего набора из test.csv, иначе - сплитованный набор базы из авто.ру со всеми ценами\n",
    "        if isScaler:\n",
    "            alg = self.algs[algname]\n",
    "        else:\n",
    "            alg = self.algs[algname+\"_\"]\n",
    "        if isX_sub:\n",
    "            if isScaler:\n",
    "                return alg.predict(self.X_sub_)\n",
    "            else:\n",
    "                return alg.predict(self.X_sub)\n",
    "        else:\n",
    "            if isScaler:\n",
    "                alg.fit(self.X_train_, self.y_train_)\n",
    "                return alg.predict(self.X_test_)\n",
    "            else:\n",
    "                alg.fit(self.X_train, self.y_train)\n",
    "                return alg.predict(self.X_test)\n",
    "\n",
    "    def setp(self, algname, **params):  # установить гиперпараметры для р егрессора в словаре\n",
    "        self.algs[algname].set_params(**params)\n",
    "        for qq in params:\n",
    "            print(str(self.algs[algname].get_params()[qq]), end=\" \")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def fullname_(self, algname):  # вывести имя регрессора, соответствующее короткому имени\n",
    "        return str(alg.algs[algname]).split(\".\")[-1].rstrip(\"'>\")\n",
    "\n",
    "    # запустил только 1 раз для RandomForestregressor - работало несколько часов, закончило где-то ночью неизвестно во сколько\n",
    "    def SearchCV(self, algname, isScaler=False, rf_random=None):  # подбор гиперпараметров\n",
    "        if isScaler:\n",
    "            alg = self.algs[algname]\n",
    "        else:\n",
    "            alg = self.algs[algname+\"_\"]\n",
    "\n",
    "        if (alg is None):\n",
    "            raise Exception('не инициализирован регрессор')\n",
    "        if rf_random is None:\n",
    "            n_estimators = [int(x) for x in np.linspace(\n",
    "                start=200, stop=2000, num=10)]\n",
    "            max_features = ['auto', 'sqrt']\n",
    "            max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "            max_depth.append(None)\n",
    "            min_samples_split = [2, 5, 10]\n",
    "            min_samples_leaf = [1, 2, 4]\n",
    "            bootstrap = [True, False]\n",
    "            random_grid = {'n_estimators': n_estimators,\n",
    "                           'max_features': max_features,\n",
    "                           'max_depth': max_depth,\n",
    "                           'min_samples_split': min_samples_split,\n",
    "                           'min_samples_leaf': min_samples_leaf,\n",
    "                           'bootstrap': bootstrap}\n",
    "            self.searchCV = RandomizedSearchCV(estimator=alg, param_distributions=random_grid, n_iter=100,\n",
    "                                               cv=3, verbose=2, random_state=RANDOM_SEED, n_jobs=-1)\n",
    "        else:\n",
    "            self.searchCV = rf_random\n",
    "\n",
    "        if isScaler:\n",
    "            self.searchCV.fit(self.X_train, self.y_train)\n",
    "        else:\n",
    "            self.searchCV.fit(self.X_train_, self.y_train_)\n",
    "        self.lastbestparams = rf_random.best_params_\n",
    "        alg.set_params(**self.lastbestparams)\n",
    "\n",
    "    # функции для стекинга\n",
    "    # здесь передаются ndarrays , а не dataframe\n",
    "    def compute_meta_feature(self, clf, X_train, X_test, y_train, cv):\n",
    "        \"\"\"\n",
    "        Computes meta-features using the regressor.\n",
    "        :arg clf: scikit-learn regressor\n",
    "        :args X_train, y_train: training set\n",
    "        :arg X_test: testing set\n",
    "        :arg cv: cross-validation folding\n",
    "        \"\"\"\n",
    "        X_meta_train = np.zeros_like(y_train, dtype=np.float32)\n",
    "        for train_fold_index, predict_fold_index in cv.split(X_train):\n",
    "            X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "            y_fold_train = y_train[train_fold_index]\n",
    "\n",
    "            folded_clf = clone(clf)\n",
    "            folded_clf.fit(X_fold_train, y_fold_train)\n",
    "            X_meta_train[predict_fold_index] = folded_clf.predict(\n",
    "                X_fold_predict)\n",
    "\n",
    "        meta_clf = clone(clf)\n",
    "        meta_clf.fit(X_train, y_train)\n",
    "\n",
    "        X_meta_test = meta_clf.predict(X_test)\n",
    "\n",
    "        return X_meta_train, X_meta_test\n",
    "\n",
    "    def generate_meta_features(self, nregressors,  cv, isScaler=False, isX_sub=False):\n",
    "        \"\"\"\n",
    "        Generates metafeatures using a list of regressors.\n",
    "        :arg regressors: list of scikit-learn regressors\n",
    "        :args X_train, y_train: training set\n",
    "        :arg X_test: testing set\n",
    "        :arg cv: cross-validation folding\n",
    "        \"\"\"\n",
    "        if isScaler:  # копия каждого регрессора для масштабированных данных хранится по имени с нижним подчеркиванием\n",
    "            regressors = [alg.algs[i+\"_\"] for i in nregressors]\n",
    "            if isX_sub:  # для рабочего набора stacked_features_train взять в качестве тренировочной всю имеющуюся базу, вытянутую из авто.ру\n",
    "                # а для тестового -stacked_features_test - данные из базы test\n",
    "                X_train, X_test, y_train = self.X_.to_numpy(\n",
    "                ), self.X_sub_.to_numpy(), self.y.to_numpy()\n",
    "            else:\n",
    "                X_train, X_test, y_train = self.X_train_.to_numpy(\n",
    "                ), self.X_test_.to_numpy(), self.y_train_.to_numpy()\n",
    "        else:\n",
    "            regressors = [alg.algs[i] for i in nregressors]\n",
    "            if isX_sub:\n",
    "                X_train, X_test, y_train = self.X.to_numpy(\n",
    "                ), self.X_sub.to_numpy(), self.y.to_numpy()\n",
    "            else:\n",
    "                X_train, X_test, y_train = self.X_train.to_numpy(\n",
    "                ), self.X_test.to_numpy(), self.y_train_.to_numpy()\n",
    "        regressorsnew = []\n",
    "        # не сбивать осуществленный fit у регрессоров,сделать их копии, т.к. для метапараметров будет другой фит\n",
    "        for rgs in regressors:\n",
    "            # гиперпараметры тоже копируются или по умолчанию встают???проверить\n",
    "            regressorsnew.append(clone(rgs))\n",
    "\n",
    "        features = [\n",
    "            self.compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
    "            for clf in tqdm(regressorsnew)\n",
    "        ]\n",
    "        tr = np.vstack([features_train for features_train,\n",
    "                       features_test in features]).T\n",
    "        tst = np.vstack([features_test for features_train,\n",
    "                        features_test in features]).T\n",
    "        if isScaler:\n",
    "            if isX_sub:\n",
    "                self.stacked_features_train_sub_ = tr\n",
    "                self.stacked_features_test_sub_ = tst\n",
    "            else:\n",
    "                self.stacked_features_train_ = tr\n",
    "                self.stacked_features_test_ = tst\n",
    "        else:\n",
    "            if isX_sub:\n",
    "                self.stacked_features_train_sub = tr\n",
    "                self.stacked_features_test_sub = tst\n",
    "            else:\n",
    "                self.stacked_features_train = tr\n",
    "                self.stacked_features_test = tst\n",
    "\n",
    "        return tr, tst\n",
    "\n",
    "    # когда приготовлены метапризнаки с помощью generate_meta_features, можно вызывать stekpredict\n",
    "    # для оценки метрики traintest и для рабочего набора test.csv надо отдельно вызывать generate_meta_features\n",
    "    def stekpredict(self, algname, isScaler=False, isX_sub=False):\n",
    "        if isScaler:\n",
    "            alg = clone(self.algs[algname+\"_\"])\n",
    "        else:\n",
    "            alg = clone(self.algs[algname])\n",
    "\n",
    "        if isX_sub:\n",
    "            if isScaler:\n",
    "                alg.fit(self.stacked_features_train_sub_, self.y)\n",
    "                return alg.predict(self.stacked_features_test_sub_)\n",
    "            else:\n",
    "                alg.fit(self.stacked_features_train_sub, self.y)\n",
    "                return alg.predict(self.stacked_features_test_sub)\n",
    "        else:\n",
    "            if isScaler:\n",
    "                alg.fit(self.stacked_features_train_, self.y_train_)\n",
    "                return alg.predict(self.stacked_features_test_)\n",
    "            else:\n",
    "                alg.fit(self.stacked_features_train, self.y_train)\n",
    "                return alg.predict(self.stacked_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      220000.0\n",
       "1      490000.0\n",
       "2      180000.0\n",
       "3      480000.0\n",
       "4      440000.0\n",
       "5     2520000.0\n",
       "6     4220000.0\n",
       "7      440000.0\n",
       "8    10800000.0\n",
       "9      630000.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=np.log(y)[:10]\n",
    "qq=np.exp(q)\n",
    "qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "XGB\n",
      "DTR\n",
      "RFR\n",
      "Ada\n",
      "GBoo\n"
     ]
    }
   ],
   "source": [
    "# создать класс -обертку для работы с регрессорами\n",
    "alg = AlgRegressor(data_my, np.log(y), cat_features_ids)\n",
    "# добавление разных регрессоров\n",
    "alg.addalg('LR', LinearRegression())\n",
    "alg.addalg('XGB', xg.XGBRegressor())\n",
    "\n",
    "alg.addalg('DTR', DecisionTreeRegressor(random_state=RANDOM_SEED,\n",
    "           max_depth=14))  # наилучшая глубина подобрана перебором\n",
    "alg.addalg('RFR', RandomForestRegressor(random_state=RANDOM_SEED))\n",
    "alg.addalg('Ada', AdaBoostRegressor(random_state=RANDOM_SEED))\n",
    "alg.addalg('GBoo', GradientBoostingRegressor(learning_rate=0.1, n_estimators=100,\n",
    "                                             max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1, max_features=int(len(data_my.columns)/3), random_state=RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка для выбранного алгоритма на немасштабированных и масштабированных признаках\n",
    "def predictionresult(algname):\n",
    "    predict = (alg.fitpredict(algname), alg.fitpredict(algname, isScaler=True))\n",
    "    print(\"Точность {}/(StandardScaler) по метрике MAPE,%: {:0.2f}/{:0.2f}\".format(alg.fullname_(algname),\n",
    "                                                mean_absolute_percentage_error(\n",
    "                                                    np.exp(alg.y_test_), np.exp(predict[0]))*100,\n",
    "                                                mean_absolute_percentage_error(np.exp(alg.y_test), np.exp(predict[1]))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность LinearRegression()/(StandardScaler) по метрике MAPE,%: 30.39/30.42\n",
      "Точность 300000012,\n",
      "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "             validate_parameters=1, verbosity=None)/(StandardScaler) по метрике MAPE,%: 16.75/16.77\n",
      "1200 10 4 sqrt 20 \n",
      "\n",
      "Точность GradientBoostingRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=4,\n",
      "                          min_samples_split=10, n_estimators=1200,\n",
      "                          random_state=42, subsample=1)/(StandardScaler) по метрике MAPE,%: 20.87/16.60\n",
      "Точность DecisionTreeRegressor(max_depth=14, random_state=42)/(StandardScaler) по метрике MAPE,%: 22.85/23.36\n",
      "Точность RandomForestRegressor(random_state=42)/(StandardScaler) по метрике MAPE,%: 16.50/16.56\n"
     ]
    }
   ],
   "source": [
    "# линейная регрессия хуже остальных алгоритмов предсказывает\n",
    "predictionresult('LR')\n",
    "# predictionresult('Ada') #показывает MAPE на порядок хуже остальных -чета не то, не успел выяснить\n",
    "\n",
    "# predictionresult('GBoo') #из коробки хуже, чем с подобранными гиперпараметрами для RandomForestRegressor\n",
    "predictionresult('XGB') \n",
    "\n",
    "bparams = {'n_estimators': 1200, 'min_samples_split': 10,\n",
    "           'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20}\n",
    "alg.setp('GBoo', **bparams)\n",
    "predictionresult('GBoo')\n",
    "\n",
    "predictionresult('DTR')  # 22.99% /23.20% при max_depth=14\n",
    "# точность RandomForestRegressor по MAPE из коробки получилась выше, чем с подбором гиперпараметров\n",
    "predictionresult('RFR')\n",
    "# всю ночь выполнялся перебор alg.SearchCV('RFR')\n",
    "# но лучших результатов не получилось\n",
    "# Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
    "# для RandomForestRegressor подобраны гиперпараметры:\n",
    "# {'n_estimators': 1200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n",
    "# bparams={'n_estimators': 1200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n",
    "# alg.setp('RFR',**bparams)\n",
    "# predictionresult('RFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a68476c7124e85ae5ed1fe782b5872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0654e36dc5ff44dd88e348618f030455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2502e9c10a4420a85b80fc41e0b1485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85331b754be54acb89a08dffb4ae83d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# запуск стекинга для 4х регрессоров, делающих метапризнаки\n",
    "nalgs = ['DTR', 'XGB', 'RFR', 'GBoo']  # ,'RFR','GBoo'\n",
    "stacked_features_train_, stacked_features_test_ = alg.generate_meta_features(\n",
    "    nalgs, cv, isScaler=True)\n",
    "stacked_features_train, stacked_features_test = alg.generate_meta_features(\n",
    "    nalgs, cv)\n",
    "\n",
    "stacked_features_train_sub_, stacked_features_test_sub_ = alg.generate_meta_features(\n",
    "    nalgs, cv, isScaler=True,isX_sub=True)\n",
    "stacked_features_train_sub, stacked_features_test_sub = alg.generate_meta_features(\n",
    "    nalgs, cv,isX_sub=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GBoo', 'DTR', 'XGB', 'RFR', 'LR']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nalgs = ['GBoo','DTR', 'XGB', 'RFR']\n",
    "nalgs.append('LR')\n",
    "nalgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoo\n",
      "GBoo\n",
      "Точность стекинг для GradientBoostingRegressor(random_state=42)/(StandardScaler) по метрике MAPE,%: 15.83/16.11\n",
      "DTR\n",
      "Точность стекинг для DecisionTreeRegressor(max_depth=14, random_state=42)/(StandardScaler) по метрике MAPE,%: 19.85/19.47\n",
      "XGB\n",
      "Точность стекинг для 300000012,\n",
      "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "             validate_parameters=1, verbosity=None)/(StandardScaler) по метрике MAPE,%: 16.52/16.72\n",
      "RFR\n",
      "Точность стекинг для RandomForestRegressor(random_state=42)/(StandardScaler) по метрике MAPE,%: 16.60/16.80\n",
      "LR\n",
      "Точность стекинг для LinearRegression()/(StandardScaler) по метрике MAPE,%: 15.66/15.90\n"
     ]
    }
   ],
   "source": [
    "# опробование на метапараметрах каждого из регрессоров,\n",
    "# из которых эти метапараметры генерировались.\n",
    "\n",
    "predict=None\n",
    "predict_sub=None\n",
    "\n",
    "for Alg in nalgs:\n",
    "    print(Alg)\n",
    "    if Alg=='GBoo':\n",
    "        # а GradientBoostingRegressor заупрямился и потребовал max_features must be in (0, n_features]\n",
    "        # не помогало ни sqrt, ни auto - пришлось для него сбросить 'max_features': None,\n",
    "        # - только при этом выдал результат MAPE,%: 19.50/20.15\n",
    "        alg.addalg('GBoo', GradientBoostingRegressor(random_state=RANDOM_SEED))     \n",
    "    predict = (alg.stekpredict(Alg), alg.stekpredict(Alg, isScaler=True))\n",
    "    print(\"Точность стекинг для {}/(StandardScaler) по метрике MAPE,%: {:0.2f}/{:0.2f}\".format(alg.fullname_(Alg),\n",
    "                            mean_absolute_percentage_error(\n",
    "                                np.exp(alg.y_test_), np.exp(predict[0]))*100,\n",
    "                            mean_absolute_percentage_error(np.exp(alg.y_test_), np.exp(predict[1]))*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alg='LR'\n",
    "predict_sub = alg.stekpredict(Alg,isX_sub=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['price'] = predict_sub\n",
    "sample_submission.to_csv(f'submission_myds_stek_logy.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# оказалось лучший результат: \n",
    "внешний регрессор, который отрабатывает на метапризнаках -LinearRegression\n",
    "\n",
    "Точность стекинг для LinearRegression()/(StandardScaler) по метрике MAPE,%: 17.73/19.63\n",
    "\n",
    "но на kaggle выложу пока катбуст, уже дедлайн наступил. позже пересчитаю через стекинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037164,
     "end_time": "2020-10-26T12:47:03.997616",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.960452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # Model 2 : CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# с катбустом много вопросов.\n",
    "# с одной стороны он сразу дал хороший результат на малом количестве признаков.\n",
    "# с другой стороны - ядро питон умирает по счету раз, если добавлять некоторые признаки.\n",
    "# самое непонятное - безобидный признак fuelType, которого всего 4 значения уверенно рушил работу катбуста,\n",
    "# даже при минимальном наборе\n",
    "# cat_features_ids=['bodyType', 'brand', 'color','fuelType']\n",
    "# было перепробовано много комбинаций признаков, самый найденный длинный список\n",
    "# ['Руль', 'Владельцы', 'color', 'enginePower', 'brand', 'bodyType', 'engineDisplacement', 'vehicleConfiguration', 'model_name', 'numberOfDoors', 'name']\n",
    "# при добавлении новых признаков - ядро сразу умирает при запуске fit\n",
    "# а с признаком fuelType ядро умирает при очень коротком списке признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12360/2046344508.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_my['sample'] = 1 # помечаем где у нас трейн\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12360/2046344508.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['sample'] = 0 # помечаем где у нас тест\n"
     ]
    }
   ],
   "source": [
    "# выбрать подмножество признаков, которое не рушит катбуст\n",
    "columns_my = ['bodyType', 'brand', 'color', 'Владельцы',\n",
    "              'engineDisplacement', 'enginePower',\n",
    "              'mileage',     'modelDate', 'model_name',\n",
    "              'name', 'numberOfDoors',\n",
    "              'productionDate',   'vehicleConfiguration', 'Руль'\n",
    "              ]\n",
    "columns_my = ['model_name', 'enginePower', 'brand', 'name',\n",
    "              'vehicleConfiguration', 'engineDisplacement', 'bodyType']\n",
    "# приготовить категориальные признаки для катбуста\n",
    "# обрезать полный набор cat_features_ids (определен выше) в соответствии с тем, сколько столбцов я оставил в работу\n",
    "cat_features_ids = list(set(columns_my).intersection(set(cat_features_ids)))\n",
    "\n",
    "df_train_my = train_my[columns_my]\n",
    "df_test = test[columns_my]\n",
    "y = train_my['priceadapt']\n",
    "\n",
    "df_train_my['sample'] = 1  # помечаем где у нас трейн\n",
    "df_test['sample'] = 0  # помечаем где у нас тест\n",
    "data_my = df_test.append(df_train_my, sort=False).reset_index(\n",
    "    drop=True)  # объединяем\n",
    "\n",
    "X = data_my.query('sample == 1').drop(['sample'], axis=1)\n",
    "X_sub = data_my.query('sample == 0').drop(['sample'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.030553\n",
      "0:\tlearn: 0.0504515\ttest: 0.0507964\tbest: 0.0507964 (0)\ttotal: 371ms\tremaining: 30m 55s\n",
      "20:\tlearn: 0.0384732\ttest: 0.0383104\tbest: 0.0383104 (20)\ttotal: 2.79s\tremaining: 11m\n",
      "40:\tlearn: 0.0325580\ttest: 0.0318106\tbest: 0.0318106 (40)\ttotal: 5.11s\tremaining: 10m 17s\n",
      "60:\tlearn: 0.0295638\ttest: 0.0283222\tbest: 0.0283222 (60)\ttotal: 7.65s\tremaining: 10m 19s\n",
      "80:\tlearn: 0.0281920\ttest: 0.0267296\tbest: 0.0267296 (80)\ttotal: 9.96s\tremaining: 10m 5s\n",
      "100:\tlearn: 0.0273921\ttest: 0.0257961\tbest: 0.0257961 (100)\ttotal: 12.3s\tremaining: 9m 55s\n",
      "120:\tlearn: 0.0268667\ttest: 0.0252638\tbest: 0.0252638 (120)\ttotal: 14.6s\tremaining: 9m 48s\n",
      "140:\tlearn: 0.0264740\ttest: 0.0248711\tbest: 0.0248711 (140)\ttotal: 17.1s\tremaining: 9m 48s\n",
      "160:\tlearn: 0.0261530\ttest: 0.0245624\tbest: 0.0245624 (160)\ttotal: 19.6s\tremaining: 9m 47s\n",
      "180:\tlearn: 0.0258508\ttest: 0.0242867\tbest: 0.0242867 (180)\ttotal: 22.3s\tremaining: 9m 54s\n",
      "200:\tlearn: 0.0255605\ttest: 0.0239911\tbest: 0.0239911 (200)\ttotal: 25s\tremaining: 9m 58s\n",
      "220:\tlearn: 0.0253328\ttest: 0.0237713\tbest: 0.0237713 (220)\ttotal: 27.6s\tremaining: 9m 57s\n",
      "240:\tlearn: 0.0251328\ttest: 0.0235893\tbest: 0.0235893 (240)\ttotal: 30.2s\tremaining: 9m 57s\n",
      "260:\tlearn: 0.0249316\ttest: 0.0234097\tbest: 0.0234097 (260)\ttotal: 32.8s\tremaining: 9m 55s\n",
      "280:\tlearn: 0.0247074\ttest: 0.0231995\tbest: 0.0231995 (280)\ttotal: 35.2s\tremaining: 9m 51s\n",
      "300:\tlearn: 0.0244994\ttest: 0.0230228\tbest: 0.0230228 (300)\ttotal: 39.1s\tremaining: 10m 10s\n",
      "320:\tlearn: 0.0243109\ttest: 0.0228562\tbest: 0.0228562 (320)\ttotal: 41.7s\tremaining: 10m 8s\n",
      "340:\tlearn: 0.0241376\ttest: 0.0227043\tbest: 0.0227043 (340)\ttotal: 44.3s\tremaining: 10m 4s\n",
      "360:\tlearn: 0.0239691\ttest: 0.0225551\tbest: 0.0225551 (360)\ttotal: 46.9s\tremaining: 10m 2s\n",
      "380:\tlearn: 0.0238115\ttest: 0.0224125\tbest: 0.0224125 (380)\ttotal: 49.3s\tremaining: 9m 57s\n",
      "400:\tlearn: 0.0236910\ttest: 0.0223048\tbest: 0.0223048 (400)\ttotal: 51.8s\tremaining: 9m 54s\n",
      "420:\tlearn: 0.0235704\ttest: 0.0221995\tbest: 0.0221995 (420)\ttotal: 54.2s\tremaining: 9m 49s\n",
      "440:\tlearn: 0.0234492\ttest: 0.0221033\tbest: 0.0221033 (440)\ttotal: 56.7s\tremaining: 9m 46s\n",
      "460:\tlearn: 0.0233273\ttest: 0.0220019\tbest: 0.0220019 (460)\ttotal: 59.2s\tremaining: 9m 42s\n",
      "480:\tlearn: 0.0232289\ttest: 0.0219191\tbest: 0.0219191 (480)\ttotal: 1m 1s\tremaining: 9m 39s\n",
      "500:\tlearn: 0.0231361\ttest: 0.0218581\tbest: 0.0218581 (500)\ttotal: 1m 4s\tremaining: 9m 35s\n",
      "520:\tlearn: 0.0230476\ttest: 0.0217937\tbest: 0.0217937 (520)\ttotal: 1m 6s\tremaining: 9m 35s\n",
      "540:\tlearn: 0.0229633\ttest: 0.0217382\tbest: 0.0217382 (540)\ttotal: 1m 9s\tremaining: 9m 34s\n",
      "560:\tlearn: 0.0228735\ttest: 0.0216754\tbest: 0.0216754 (560)\ttotal: 1m 12s\tremaining: 9m 31s\n",
      "580:\tlearn: 0.0227910\ttest: 0.0216145\tbest: 0.0216145 (580)\ttotal: 1m 14s\tremaining: 9m 28s\n",
      "600:\tlearn: 0.0227103\ttest: 0.0215483\tbest: 0.0215483 (600)\ttotal: 1m 17s\tremaining: 9m 26s\n",
      "620:\tlearn: 0.0226236\ttest: 0.0214934\tbest: 0.0214934 (620)\ttotal: 1m 19s\tremaining: 9m 22s\n",
      "640:\tlearn: 0.0225435\ttest: 0.0214385\tbest: 0.0214385 (640)\ttotal: 1m 22s\tremaining: 9m 19s\n",
      "660:\tlearn: 0.0224638\ttest: 0.0213909\tbest: 0.0213909 (660)\ttotal: 1m 24s\tremaining: 9m 15s\n",
      "680:\tlearn: 0.0223791\ttest: 0.0213324\tbest: 0.0213324 (680)\ttotal: 1m 27s\tremaining: 9m 12s\n",
      "700:\tlearn: 0.0223000\ttest: 0.0212838\tbest: 0.0212838 (700)\ttotal: 1m 29s\tremaining: 9m 9s\n",
      "720:\tlearn: 0.0222275\ttest: 0.0212264\tbest: 0.0212264 (720)\ttotal: 1m 32s\tremaining: 9m 7s\n",
      "740:\tlearn: 0.0221584\ttest: 0.0211785\tbest: 0.0211785 (740)\ttotal: 1m 35s\tremaining: 9m 6s\n",
      "760:\tlearn: 0.0220994\ttest: 0.0211414\tbest: 0.0211414 (760)\ttotal: 1m 37s\tremaining: 9m 3s\n",
      "780:\tlearn: 0.0220284\ttest: 0.0210907\tbest: 0.0210907 (780)\ttotal: 1m 40s\tremaining: 9m\n",
      "800:\tlearn: 0.0219735\ttest: 0.0210624\tbest: 0.0210624 (800)\ttotal: 1m 42s\tremaining: 8m 57s\n",
      "820:\tlearn: 0.0219196\ttest: 0.0210344\tbest: 0.0210344 (820)\ttotal: 1m 45s\tremaining: 8m 54s\n",
      "840:\tlearn: 0.0218591\ttest: 0.0209995\tbest: 0.0209995 (840)\ttotal: 1m 47s\tremaining: 8m 51s\n",
      "860:\tlearn: 0.0218087\ttest: 0.0209724\tbest: 0.0209724 (860)\ttotal: 1m 50s\tremaining: 8m 49s\n",
      "880:\tlearn: 0.0217579\ttest: 0.0209446\tbest: 0.0209446 (880)\ttotal: 1m 52s\tremaining: 8m 46s\n",
      "900:\tlearn: 0.0217044\ttest: 0.0209151\tbest: 0.0209151 (900)\ttotal: 1m 54s\tremaining: 8m 42s\n",
      "920:\tlearn: 0.0216433\ttest: 0.0208789\tbest: 0.0208789 (920)\ttotal: 1m 57s\tremaining: 8m 40s\n",
      "940:\tlearn: 0.0215902\ttest: 0.0208401\tbest: 0.0208401 (940)\ttotal: 2m\tremaining: 8m 38s\n",
      "960:\tlearn: 0.0215453\ttest: 0.0208135\tbest: 0.0208135 (960)\ttotal: 2m 2s\tremaining: 8m 35s\n",
      "980:\tlearn: 0.0214943\ttest: 0.0207933\tbest: 0.0207933 (980)\ttotal: 2m 5s\tremaining: 8m 32s\n",
      "1000:\tlearn: 0.0214453\ttest: 0.0207591\tbest: 0.0207591 (1000)\ttotal: 2m 7s\tremaining: 8m 30s\n",
      "1020:\tlearn: 0.0214021\ttest: 0.0207359\tbest: 0.0207359 (1020)\ttotal: 2m 10s\tremaining: 8m 27s\n",
      "1040:\tlearn: 0.0213524\ttest: 0.0207075\tbest: 0.0207075 (1040)\ttotal: 2m 12s\tremaining: 8m 24s\n",
      "1060:\tlearn: 0.0213085\ttest: 0.0206845\tbest: 0.0206845 (1060)\ttotal: 2m 15s\tremaining: 8m 21s\n",
      "1080:\tlearn: 0.0212587\ttest: 0.0206573\tbest: 0.0206573 (1080)\ttotal: 2m 17s\tremaining: 8m 18s\n",
      "1100:\tlearn: 0.0212144\ttest: 0.0206378\tbest: 0.0206378 (1100)\ttotal: 2m 20s\tremaining: 8m 15s\n",
      "1120:\tlearn: 0.0211638\ttest: 0.0206181\tbest: 0.0206181 (1120)\ttotal: 2m 22s\tremaining: 8m 13s\n",
      "1140:\tlearn: 0.0211236\ttest: 0.0206006\tbest: 0.0206006 (1140)\ttotal: 2m 25s\tremaining: 8m 10s\n",
      "1160:\tlearn: 0.0210840\ttest: 0.0205831\tbest: 0.0205831 (1160)\ttotal: 2m 27s\tremaining: 8m 8s\n",
      "1180:\tlearn: 0.0210418\ttest: 0.0205578\tbest: 0.0205570 (1179)\ttotal: 2m 30s\tremaining: 8m 5s\n",
      "1200:\tlearn: 0.0210048\ttest: 0.0205403\tbest: 0.0205403 (1200)\ttotal: 2m 33s\tremaining: 8m 4s\n",
      "1220:\tlearn: 0.0209682\ttest: 0.0205242\tbest: 0.0205239 (1219)\ttotal: 2m 35s\tremaining: 8m 2s\n",
      "1240:\tlearn: 0.0209279\ttest: 0.0205063\tbest: 0.0205063 (1240)\ttotal: 2m 38s\tremaining: 7m 59s\n",
      "1260:\tlearn: 0.0208878\ttest: 0.0204923\tbest: 0.0204923 (1260)\ttotal: 2m 40s\tremaining: 7m 56s\n",
      "1280:\tlearn: 0.0208512\ttest: 0.0204765\tbest: 0.0204765 (1279)\ttotal: 2m 43s\tremaining: 7m 53s\n",
      "1300:\tlearn: 0.0208125\ttest: 0.0204581\tbest: 0.0204581 (1300)\ttotal: 2m 45s\tremaining: 7m 51s\n",
      "1320:\tlearn: 0.0207803\ttest: 0.0204446\tbest: 0.0204446 (1320)\ttotal: 2m 48s\tremaining: 7m 48s\n",
      "1340:\tlearn: 0.0207391\ttest: 0.0204200\tbest: 0.0204200 (1340)\ttotal: 2m 50s\tremaining: 7m 45s\n",
      "1360:\tlearn: 0.0207075\ttest: 0.0204058\tbest: 0.0204054 (1359)\ttotal: 2m 53s\tremaining: 7m 42s\n",
      "1380:\tlearn: 0.0206663\ttest: 0.0203821\tbest: 0.0203821 (1380)\ttotal: 2m 55s\tremaining: 7m 40s\n",
      "1400:\tlearn: 0.0206361\ttest: 0.0203683\tbest: 0.0203683 (1400)\ttotal: 2m 58s\tremaining: 7m 37s\n",
      "1420:\tlearn: 0.0206015\ttest: 0.0203471\tbest: 0.0203469 (1419)\ttotal: 3m\tremaining: 7m 35s\n",
      "1440:\tlearn: 0.0205598\ttest: 0.0203281\tbest: 0.0203281 (1440)\ttotal: 3m 3s\tremaining: 7m 32s\n",
      "1460:\tlearn: 0.0205122\ttest: 0.0203063\tbest: 0.0203063 (1460)\ttotal: 3m 5s\tremaining: 7m 30s\n",
      "1480:\tlearn: 0.0204711\ttest: 0.0202917\tbest: 0.0202917 (1480)\ttotal: 3m 8s\tremaining: 7m 27s\n",
      "1500:\tlearn: 0.0204373\ttest: 0.0202828\tbest: 0.0202827 (1498)\ttotal: 3m 10s\tremaining: 7m 24s\n",
      "1520:\tlearn: 0.0204042\ttest: 0.0202625\tbest: 0.0202625 (1520)\ttotal: 3m 13s\tremaining: 7m 21s\n",
      "1540:\tlearn: 0.0203673\ttest: 0.0202433\tbest: 0.0202433 (1540)\ttotal: 3m 15s\tremaining: 7m 19s\n",
      "1560:\tlearn: 0.0203315\ttest: 0.0202238\tbest: 0.0202238 (1560)\ttotal: 3m 18s\tremaining: 7m 16s\n",
      "1580:\tlearn: 0.0203009\ttest: 0.0202111\tbest: 0.0202111 (1580)\ttotal: 3m 20s\tremaining: 7m 14s\n",
      "1600:\tlearn: 0.0202691\ttest: 0.0201967\tbest: 0.0201967 (1600)\ttotal: 3m 23s\tremaining: 7m 12s\n",
      "1620:\tlearn: 0.0202392\ttest: 0.0201898\tbest: 0.0201898 (1620)\ttotal: 3m 26s\tremaining: 7m 10s\n",
      "1640:\tlearn: 0.0202105\ttest: 0.0201779\tbest: 0.0201779 (1640)\ttotal: 3m 29s\tremaining: 7m 8s\n",
      "1660:\tlearn: 0.0201831\ttest: 0.0201676\tbest: 0.0201676 (1660)\ttotal: 3m 31s\tremaining: 7m 5s\n",
      "1680:\tlearn: 0.0201557\ttest: 0.0201585\tbest: 0.0201585 (1680)\ttotal: 3m 34s\tremaining: 7m 2s\n",
      "1700:\tlearn: 0.0201312\ttest: 0.0201460\tbest: 0.0201460 (1700)\ttotal: 3m 36s\tremaining: 7m\n",
      "1720:\tlearn: 0.0201031\ttest: 0.0201329\tbest: 0.0201329 (1720)\ttotal: 3m 39s\tremaining: 6m 57s\n",
      "1740:\tlearn: 0.0200741\ttest: 0.0201231\tbest: 0.0201231 (1740)\ttotal: 3m 42s\tremaining: 6m 56s\n",
      "1760:\tlearn: 0.0200457\ttest: 0.0201108\tbest: 0.0201106 (1759)\ttotal: 3m 44s\tremaining: 6m 53s\n",
      "1780:\tlearn: 0.0200188\ttest: 0.0201011\tbest: 0.0201003 (1779)\ttotal: 3m 47s\tremaining: 6m 50s\n",
      "1800:\tlearn: 0.0199940\ttest: 0.0200885\tbest: 0.0200885 (1800)\ttotal: 3m 49s\tremaining: 6m 48s\n",
      "1820:\tlearn: 0.0199628\ttest: 0.0200793\tbest: 0.0200793 (1820)\ttotal: 3m 52s\tremaining: 6m 45s\n",
      "1840:\tlearn: 0.0199385\ttest: 0.0200663\tbest: 0.0200663 (1840)\ttotal: 3m 54s\tremaining: 6m 43s\n",
      "1860:\tlearn: 0.0199088\ttest: 0.0200571\tbest: 0.0200570 (1854)\ttotal: 3m 57s\tremaining: 6m 40s\n",
      "1880:\tlearn: 0.0198789\ttest: 0.0200423\tbest: 0.0200423 (1880)\ttotal: 4m\tremaining: 6m 38s\n",
      "1900:\tlearn: 0.0198540\ttest: 0.0200350\tbest: 0.0200343 (1899)\ttotal: 4m 3s\tremaining: 6m 36s\n",
      "1920:\tlearn: 0.0198283\ttest: 0.0200289\tbest: 0.0200289 (1920)\ttotal: 4m 5s\tremaining: 6m 34s\n",
      "1940:\tlearn: 0.0198004\ttest: 0.0200186\tbest: 0.0200186 (1940)\ttotal: 4m 9s\tremaining: 6m 33s\n",
      "1960:\tlearn: 0.0197736\ttest: 0.0200047\tbest: 0.0200047 (1960)\ttotal: 4m 12s\tremaining: 6m 31s\n",
      "1980:\tlearn: 0.0197475\ttest: 0.0199934\tbest: 0.0199934 (1980)\ttotal: 4m 15s\tremaining: 6m 30s\n",
      "2000:\tlearn: 0.0197199\ttest: 0.0199813\tbest: 0.0199813 (2000)\ttotal: 4m 19s\tremaining: 6m 28s\n",
      "2020:\tlearn: 0.0197017\ttest: 0.0199723\tbest: 0.0199723 (2020)\ttotal: 4m 23s\tremaining: 6m 27s\n",
      "2040:\tlearn: 0.0196706\ttest: 0.0199627\tbest: 0.0199627 (2040)\ttotal: 4m 25s\tremaining: 6m 25s\n",
      "2060:\tlearn: 0.0196491\ttest: 0.0199563\tbest: 0.0199563 (2060)\ttotal: 4m 28s\tremaining: 6m 22s\n",
      "2080:\tlearn: 0.0196210\ttest: 0.0199444\tbest: 0.0199444 (2080)\ttotal: 4m 31s\tremaining: 6m 20s\n",
      "2100:\tlearn: 0.0195964\ttest: 0.0199389\tbest: 0.0199389 (2100)\ttotal: 4m 33s\tremaining: 6m 17s\n",
      "2120:\tlearn: 0.0195681\ttest: 0.0199312\tbest: 0.0199312 (2120)\ttotal: 4m 36s\tremaining: 6m 14s\n",
      "2140:\tlearn: 0.0195457\ttest: 0.0199254\tbest: 0.0199247 (2139)\ttotal: 4m 38s\tremaining: 6m 12s\n",
      "2160:\tlearn: 0.0195226\ttest: 0.0199196\tbest: 0.0199196 (2160)\ttotal: 4m 41s\tremaining: 6m 10s\n",
      "2180:\tlearn: 0.0194955\ttest: 0.0199068\tbest: 0.0199068 (2180)\ttotal: 4m 46s\tremaining: 6m 10s\n",
      "2200:\tlearn: 0.0194688\ttest: 0.0198990\tbest: 0.0198990 (2200)\ttotal: 4m 50s\tremaining: 6m 9s\n",
      "2220:\tlearn: 0.0194416\ttest: 0.0198900\tbest: 0.0198900 (2219)\ttotal: 4m 54s\tremaining: 6m 8s\n",
      "2240:\tlearn: 0.0194234\ttest: 0.0198857\tbest: 0.0198857 (2240)\ttotal: 4m 58s\tremaining: 6m 7s\n",
      "2260:\tlearn: 0.0194041\ttest: 0.0198835\tbest: 0.0198834 (2259)\ttotal: 5m 1s\tremaining: 6m 5s\n",
      "2280:\tlearn: 0.0193801\ttest: 0.0198744\tbest: 0.0198744 (2280)\ttotal: 5m 4s\tremaining: 6m 3s\n",
      "2300:\tlearn: 0.0193602\ttest: 0.0198692\tbest: 0.0198681 (2297)\ttotal: 5m 8s\tremaining: 6m 1s\n",
      "2320:\tlearn: 0.0193399\ttest: 0.0198622\tbest: 0.0198620 (2317)\ttotal: 5m 11s\tremaining: 5m 59s\n",
      "2340:\tlearn: 0.0193158\ttest: 0.0198589\tbest: 0.0198588 (2339)\ttotal: 5m 14s\tremaining: 5m 56s\n",
      "2360:\tlearn: 0.0192919\ttest: 0.0198449\tbest: 0.0198449 (2360)\ttotal: 5m 19s\tremaining: 5m 56s\n",
      "2380:\tlearn: 0.0192689\ttest: 0.0198364\tbest: 0.0198364 (2380)\ttotal: 5m 24s\tremaining: 5m 57s\n",
      "2400:\tlearn: 0.0192470\ttest: 0.0198232\tbest: 0.0198232 (2400)\ttotal: 5m 28s\tremaining: 5m 55s\n",
      "2420:\tlearn: 0.0192204\ttest: 0.0198173\tbest: 0.0198173 (2420)\ttotal: 5m 35s\tremaining: 5m 57s\n",
      "2440:\tlearn: 0.0191967\ttest: 0.0198094\tbest: 0.0198094 (2440)\ttotal: 5m 42s\tremaining: 5m 59s\n",
      "2460:\tlearn: 0.0191774\ttest: 0.0198029\tbest: 0.0198029 (2460)\ttotal: 5m 45s\tremaining: 5m 56s\n",
      "2480:\tlearn: 0.0191547\ttest: 0.0197946\tbest: 0.0197946 (2480)\ttotal: 5m 49s\tremaining: 5m 54s\n",
      "2500:\tlearn: 0.0191303\ttest: 0.0197869\tbest: 0.0197869 (2500)\ttotal: 5m 53s\tremaining: 5m 53s\n",
      "2520:\tlearn: 0.0191105\ttest: 0.0197794\tbest: 0.0197794 (2520)\ttotal: 6m\tremaining: 5m 54s\n",
      "2540:\tlearn: 0.0190862\ttest: 0.0197729\tbest: 0.0197729 (2540)\ttotal: 6m 4s\tremaining: 5m 52s\n",
      "2560:\tlearn: 0.0190649\ttest: 0.0197654\tbest: 0.0197654 (2559)\ttotal: 6m 8s\tremaining: 5m 50s\n",
      "2580:\tlearn: 0.0190477\ttest: 0.0197581\tbest: 0.0197581 (2580)\ttotal: 6m 11s\tremaining: 5m 48s\n",
      "2600:\tlearn: 0.0190263\ttest: 0.0197516\tbest: 0.0197516 (2600)\ttotal: 6m 14s\tremaining: 5m 45s\n",
      "2620:\tlearn: 0.0190007\ttest: 0.0197439\tbest: 0.0197439 (2620)\ttotal: 6m 22s\tremaining: 5m 46s\n",
      "2640:\tlearn: 0.0189815\ttest: 0.0197387\tbest: 0.0197383 (2639)\ttotal: 6m 25s\tremaining: 5m 44s\n",
      "2660:\tlearn: 0.0189634\ttest: 0.0197306\tbest: 0.0197306 (2660)\ttotal: 6m 28s\tremaining: 5m 41s\n",
      "2680:\tlearn: 0.0189435\ttest: 0.0197278\tbest: 0.0197278 (2680)\ttotal: 6m 30s\tremaining: 5m 37s\n",
      "2700:\tlearn: 0.0189215\ttest: 0.0197218\tbest: 0.0197218 (2700)\ttotal: 6m 33s\tremaining: 5m 34s\n",
      "2720:\tlearn: 0.0189019\ttest: 0.0197159\tbest: 0.0197155 (2718)\ttotal: 6m 35s\tremaining: 5m 31s\n",
      "2740:\tlearn: 0.0188806\ttest: 0.0197064\tbest: 0.0197064 (2740)\ttotal: 6m 38s\tremaining: 5m 28s\n",
      "2760:\tlearn: 0.0188605\ttest: 0.0196974\tbest: 0.0196973 (2759)\ttotal: 6m 41s\tremaining: 5m 25s\n",
      "2780:\tlearn: 0.0188366\ttest: 0.0196919\tbest: 0.0196918 (2771)\ttotal: 6m 44s\tremaining: 5m 22s\n",
      "2800:\tlearn: 0.0188174\ttest: 0.0196889\tbest: 0.0196885 (2797)\ttotal: 6m 47s\tremaining: 5m 20s\n",
      "2820:\tlearn: 0.0187982\ttest: 0.0196805\tbest: 0.0196805 (2820)\ttotal: 6m 50s\tremaining: 5m 16s\n",
      "2840:\tlearn: 0.0187747\ttest: 0.0196739\tbest: 0.0196739 (2837)\ttotal: 6m 52s\tremaining: 5m 13s\n",
      "2860:\tlearn: 0.0187510\ttest: 0.0196691\tbest: 0.0196691 (2860)\ttotal: 6m 55s\tremaining: 5m 10s\n",
      "2880:\tlearn: 0.0187297\ttest: 0.0196603\tbest: 0.0196603 (2880)\ttotal: 6m 57s\tremaining: 5m 7s\n",
      "2900:\tlearn: 0.0187020\ttest: 0.0196504\tbest: 0.0196498 (2898)\ttotal: 7m\tremaining: 5m 4s\n",
      "2920:\tlearn: 0.0186722\ttest: 0.0196417\tbest: 0.0196416 (2918)\ttotal: 7m 2s\tremaining: 5m\n",
      "2940:\tlearn: 0.0186521\ttest: 0.0196370\tbest: 0.0196370 (2940)\ttotal: 7m 5s\tremaining: 4m 57s\n",
      "2960:\tlearn: 0.0186306\ttest: 0.0196307\tbest: 0.0196302 (2958)\ttotal: 7m 7s\tremaining: 4m 54s\n",
      "2980:\tlearn: 0.0186159\ttest: 0.0196296\tbest: 0.0196296 (2980)\ttotal: 7m 10s\tremaining: 4m 51s\n",
      "3000:\tlearn: 0.0185938\ttest: 0.0196194\tbest: 0.0196186 (2997)\ttotal: 7m 13s\tremaining: 4m 48s\n",
      "3020:\tlearn: 0.0185725\ttest: 0.0196165\tbest: 0.0196165 (3020)\ttotal: 7m 15s\tremaining: 4m 45s\n",
      "3040:\tlearn: 0.0185535\ttest: 0.0196120\tbest: 0.0196120 (3040)\ttotal: 7m 19s\tremaining: 4m 42s\n",
      "3060:\tlearn: 0.0185356\ttest: 0.0196069\tbest: 0.0196056 (3059)\ttotal: 7m 21s\tremaining: 4m 39s\n",
      "3080:\tlearn: 0.0185142\ttest: 0.0195984\tbest: 0.0195984 (3080)\ttotal: 7m 24s\tremaining: 4m 36s\n",
      "3100:\tlearn: 0.0184974\ttest: 0.0195925\tbest: 0.0195924 (3099)\ttotal: 7m 27s\tremaining: 4m 33s\n",
      "3120:\tlearn: 0.0184784\ttest: 0.0195890\tbest: 0.0195886 (3119)\ttotal: 7m 31s\tremaining: 4m 31s\n",
      "3140:\tlearn: 0.0184602\ttest: 0.0195845\tbest: 0.0195844 (3136)\ttotal: 7m 33s\tremaining: 4m 28s\n",
      "3160:\tlearn: 0.0184449\ttest: 0.0195794\tbest: 0.0195794 (3160)\ttotal: 7m 37s\tremaining: 4m 26s\n",
      "3180:\tlearn: 0.0184285\ttest: 0.0195737\tbest: 0.0195737 (3180)\ttotal: 7m 40s\tremaining: 4m 23s\n",
      "3200:\tlearn: 0.0184115\ttest: 0.0195675\tbest: 0.0195673 (3198)\ttotal: 7m 43s\tremaining: 4m 20s\n",
      "3220:\tlearn: 0.0183939\ttest: 0.0195619\tbest: 0.0195619 (3220)\ttotal: 7m 45s\tremaining: 4m 17s\n",
      "3240:\tlearn: 0.0183788\ttest: 0.0195555\tbest: 0.0195550 (3239)\ttotal: 7m 48s\tremaining: 4m 14s\n",
      "3260:\tlearn: 0.0183583\ttest: 0.0195463\tbest: 0.0195458 (3258)\ttotal: 7m 53s\tremaining: 4m 12s\n",
      "3280:\tlearn: 0.0183438\ttest: 0.0195408\tbest: 0.0195408 (3280)\ttotal: 7m 56s\tremaining: 4m 9s\n",
      "3300:\tlearn: 0.0183210\ttest: 0.0195288\tbest: 0.0195285 (3299)\ttotal: 7m 59s\tremaining: 4m 6s\n",
      "3320:\tlearn: 0.0183014\ttest: 0.0195249\tbest: 0.0195238 (3314)\ttotal: 8m 1s\tremaining: 4m 3s\n",
      "3340:\tlearn: 0.0182842\ttest: 0.0195180\tbest: 0.0195180 (3340)\ttotal: 8m 4s\tremaining: 4m\n",
      "3360:\tlearn: 0.0182654\ttest: 0.0195112\tbest: 0.0195112 (3360)\ttotal: 8m 5s\tremaining: 3m 56s\n",
      "3380:\tlearn: 0.0182436\ttest: 0.0195085\tbest: 0.0195071 (3373)\ttotal: 8m 7s\tremaining: 3m 53s\n",
      "3400:\tlearn: 0.0182253\ttest: 0.0195052\tbest: 0.0195052 (3400)\ttotal: 8m 10s\tremaining: 3m 50s\n",
      "3420:\tlearn: 0.0182100\ttest: 0.0195018\tbest: 0.0195018 (3420)\ttotal: 8m 12s\tremaining: 3m 47s\n",
      "3440:\tlearn: 0.0181926\ttest: 0.0194987\tbest: 0.0194986 (3439)\ttotal: 8m 14s\tremaining: 3m 43s\n",
      "3460:\tlearn: 0.0181739\ttest: 0.0194928\tbest: 0.0194928 (3460)\ttotal: 8m 16s\tremaining: 3m 40s\n",
      "3480:\tlearn: 0.0181588\ttest: 0.0194916\tbest: 0.0194910 (3469)\ttotal: 8m 19s\tremaining: 3m 38s\n",
      "3500:\tlearn: 0.0181410\ttest: 0.0194906\tbest: 0.0194890 (3497)\ttotal: 8m 22s\tremaining: 3m 35s\n",
      "3520:\tlearn: 0.0181263\ttest: 0.0194889\tbest: 0.0194889 (3520)\ttotal: 8m 24s\tremaining: 3m 32s\n",
      "3540:\tlearn: 0.0181119\ttest: 0.0194870\tbest: 0.0194870 (3540)\ttotal: 8m 26s\tremaining: 3m 28s\n",
      "3560:\tlearn: 0.0180955\ttest: 0.0194803\tbest: 0.0194803 (3560)\ttotal: 8m 29s\tremaining: 3m 25s\n",
      "3580:\tlearn: 0.0180805\ttest: 0.0194733\tbest: 0.0194733 (3580)\ttotal: 8m 31s\tremaining: 3m 22s\n",
      "3600:\tlearn: 0.0180628\ttest: 0.0194685\tbest: 0.0194685 (3600)\ttotal: 8m 33s\tremaining: 3m 19s\n",
      "3620:\tlearn: 0.0180454\ttest: 0.0194652\tbest: 0.0194650 (3616)\ttotal: 8m 36s\tremaining: 3m 16s\n",
      "3640:\tlearn: 0.0180283\ttest: 0.0194637\tbest: 0.0194637 (3640)\ttotal: 8m 39s\tremaining: 3m 14s\n",
      "3660:\tlearn: 0.0180113\ttest: 0.0194558\tbest: 0.0194558 (3660)\ttotal: 8m 42s\tremaining: 3m 11s\n",
      "3680:\tlearn: 0.0179967\ttest: 0.0194535\tbest: 0.0194535 (3667)\ttotal: 8m 44s\tremaining: 3m 7s\n",
      "3700:\tlearn: 0.0179771\ttest: 0.0194462\tbest: 0.0194462 (3700)\ttotal: 8m 46s\tremaining: 3m 4s\n",
      "3720:\tlearn: 0.0179567\ttest: 0.0194383\tbest: 0.0194383 (3720)\ttotal: 8m 48s\tremaining: 3m 1s\n",
      "3740:\tlearn: 0.0179407\ttest: 0.0194339\tbest: 0.0194339 (3740)\ttotal: 8m 50s\tremaining: 2m 58s\n",
      "3760:\tlearn: 0.0179283\ttest: 0.0194351\tbest: 0.0194337 (3741)\ttotal: 8m 52s\tremaining: 2m 55s\n",
      "3780:\tlearn: 0.0179101\ttest: 0.0194301\tbest: 0.0194301 (3780)\ttotal: 8m 55s\tremaining: 2m 52s\n",
      "3800:\tlearn: 0.0178935\ttest: 0.0194250\tbest: 0.0194250 (3800)\ttotal: 8m 57s\tremaining: 2m 49s\n",
      "3820:\tlearn: 0.0178763\ttest: 0.0194206\tbest: 0.0194206 (3820)\ttotal: 8m 59s\tremaining: 2m 46s\n",
      "3840:\tlearn: 0.0178625\ttest: 0.0194193\tbest: 0.0194191 (3838)\ttotal: 9m 2s\tremaining: 2m 43s\n",
      "3860:\tlearn: 0.0178453\ttest: 0.0194175\tbest: 0.0194175 (3860)\ttotal: 9m 9s\tremaining: 2m 42s\n",
      "3880:\tlearn: 0.0178297\ttest: 0.0194152\tbest: 0.0194149 (3879)\ttotal: 9m 13s\tremaining: 2m 39s\n",
      "3900:\tlearn: 0.0178116\ttest: 0.0194111\tbest: 0.0194111 (3900)\ttotal: 9m 15s\tremaining: 2m 36s\n",
      "3920:\tlearn: 0.0177960\ttest: 0.0194073\tbest: 0.0194073 (3919)\ttotal: 9m 17s\tremaining: 2m 33s\n",
      "3940:\tlearn: 0.0177811\ttest: 0.0194066\tbest: 0.0194066 (3939)\ttotal: 9m 19s\tremaining: 2m 30s\n",
      "3960:\tlearn: 0.0177639\ttest: 0.0194028\tbest: 0.0194028 (3960)\ttotal: 9m 22s\tremaining: 2m 27s\n",
      "3980:\tlearn: 0.0177451\ttest: 0.0193971\tbest: 0.0193967 (3975)\ttotal: 9m 24s\tremaining: 2m 24s\n",
      "4000:\tlearn: 0.0177288\ttest: 0.0193920\tbest: 0.0193920 (4000)\ttotal: 9m 26s\tremaining: 2m 21s\n",
      "4020:\tlearn: 0.0177149\ttest: 0.0193889\tbest: 0.0193889 (4020)\ttotal: 9m 29s\tremaining: 2m 18s\n",
      "4040:\tlearn: 0.0176940\ttest: 0.0193818\tbest: 0.0193816 (4039)\ttotal: 9m 31s\tremaining: 2m 15s\n",
      "4060:\tlearn: 0.0176749\ttest: 0.0193780\tbest: 0.0193780 (4060)\ttotal: 9m 33s\tremaining: 2m 12s\n",
      "4080:\tlearn: 0.0176592\ttest: 0.0193746\tbest: 0.0193740 (4079)\ttotal: 9m 36s\tremaining: 2m 9s\n",
      "4100:\tlearn: 0.0176432\ttest: 0.0193725\tbest: 0.0193725 (4100)\ttotal: 9m 38s\tremaining: 2m 6s\n",
      "4120:\tlearn: 0.0176245\ttest: 0.0193662\tbest: 0.0193662 (4120)\ttotal: 9m 40s\tremaining: 2m 3s\n",
      "4140:\tlearn: 0.0176108\ttest: 0.0193636\tbest: 0.0193634 (4134)\ttotal: 9m 42s\tremaining: 2m\n",
      "4160:\tlearn: 0.0175944\ttest: 0.0193595\tbest: 0.0193591 (4158)\ttotal: 9m 44s\tremaining: 1m 57s\n",
      "4180:\tlearn: 0.0175815\ttest: 0.0193577\tbest: 0.0193570 (4178)\ttotal: 9m 46s\tremaining: 1m 54s\n",
      "4200:\tlearn: 0.0175676\ttest: 0.0193574\tbest: 0.0193570 (4178)\ttotal: 9m 48s\tremaining: 1m 51s\n",
      "4220:\tlearn: 0.0175496\ttest: 0.0193535\tbest: 0.0193532 (4219)\ttotal: 9m 50s\tremaining: 1m 49s\n",
      "4240:\tlearn: 0.0175343\ttest: 0.0193510\tbest: 0.0193510 (4240)\ttotal: 9m 52s\tremaining: 1m 46s\n",
      "4260:\tlearn: 0.0175210\ttest: 0.0193462\tbest: 0.0193460 (4256)\ttotal: 9m 59s\tremaining: 1m 43s\n",
      "4280:\tlearn: 0.0175081\ttest: 0.0193445\tbest: 0.0193444 (4271)\ttotal: 10m 3s\tremaining: 1m 41s\n",
      "4300:\tlearn: 0.0174928\ttest: 0.0193409\tbest: 0.0193406 (4299)\ttotal: 10m 8s\tremaining: 1m 38s\n",
      "4320:\tlearn: 0.0174766\ttest: 0.0193355\tbest: 0.0193354 (4319)\ttotal: 10m 12s\tremaining: 1m 36s\n",
      "4340:\tlearn: 0.0174622\ttest: 0.0193333\tbest: 0.0193333 (4340)\ttotal: 10m 15s\tremaining: 1m 33s\n",
      "4360:\tlearn: 0.0174467\ttest: 0.0193312\tbest: 0.0193310 (4359)\ttotal: 10m 18s\tremaining: 1m 30s\n",
      "4380:\tlearn: 0.0174332\ttest: 0.0193292\tbest: 0.0193292 (4380)\ttotal: 10m 25s\tremaining: 1m 28s\n",
      "4400:\tlearn: 0.0174162\ttest: 0.0193253\tbest: 0.0193253 (4400)\ttotal: 10m 30s\tremaining: 1m 25s\n",
      "4420:\tlearn: 0.0174008\ttest: 0.0193185\tbest: 0.0193185 (4420)\ttotal: 10m 34s\tremaining: 1m 23s\n",
      "4440:\tlearn: 0.0173888\ttest: 0.0193192\tbest: 0.0193182 (4425)\ttotal: 10m 38s\tremaining: 1m 20s\n",
      "4460:\tlearn: 0.0173736\ttest: 0.0193132\tbest: 0.0193125 (4455)\ttotal: 10m 40s\tremaining: 1m 17s\n",
      "4480:\tlearn: 0.0173590\ttest: 0.0193085\tbest: 0.0193083 (4479)\ttotal: 10m 42s\tremaining: 1m 14s\n",
      "4500:\tlearn: 0.0173473\ttest: 0.0193100\tbest: 0.0193083 (4481)\ttotal: 10m 45s\tremaining: 1m 11s\n",
      "4520:\tlearn: 0.0173320\ttest: 0.0193090\tbest: 0.0193074 (4508)\ttotal: 10m 49s\tremaining: 1m 8s\n",
      "4540:\tlearn: 0.0173187\ttest: 0.0193076\tbest: 0.0193074 (4508)\ttotal: 10m 51s\tremaining: 1m 5s\n",
      "4560:\tlearn: 0.0173005\ttest: 0.0193037\tbest: 0.0193037 (4560)\ttotal: 10m 54s\tremaining: 1m 2s\n",
      "4580:\tlearn: 0.0172883\ttest: 0.0193036\tbest: 0.0193030 (4577)\ttotal: 10m 56s\tremaining: 1m\n",
      "4600:\tlearn: 0.0172710\ttest: 0.0192983\tbest: 0.0192983 (4600)\ttotal: 10m 58s\tremaining: 57.1s\n",
      "4620:\tlearn: 0.0172569\ttest: 0.0192952\tbest: 0.0192952 (4620)\ttotal: 11m 3s\tremaining: 54.4s\n",
      "4640:\tlearn: 0.0172445\ttest: 0.0192942\tbest: 0.0192942 (4639)\ttotal: 11m 7s\tremaining: 51.6s\n",
      "4660:\tlearn: 0.0172337\ttest: 0.0192943\tbest: 0.0192933 (4651)\ttotal: 11m 12s\tremaining: 48.9s\n",
      "4680:\tlearn: 0.0172215\ttest: 0.0192900\tbest: 0.0192900 (4680)\ttotal: 11m 16s\tremaining: 46.1s\n",
      "4700:\tlearn: 0.0172080\ttest: 0.0192881\tbest: 0.0192881 (4700)\ttotal: 11m 20s\tremaining: 43.3s\n",
      "4720:\tlearn: 0.0171942\ttest: 0.0192834\tbest: 0.0192834 (4720)\ttotal: 11m 23s\tremaining: 40.4s\n",
      "4740:\tlearn: 0.0171749\ttest: 0.0192782\tbest: 0.0192778 (4737)\ttotal: 11m 25s\tremaining: 37.5s\n",
      "4760:\tlearn: 0.0171627\ttest: 0.0192757\tbest: 0.0192756 (4759)\ttotal: 11m 27s\tremaining: 34.5s\n",
      "4780:\tlearn: 0.0171489\ttest: 0.0192745\tbest: 0.0192740 (4778)\ttotal: 11m 30s\tremaining: 31.6s\n",
      "4800:\tlearn: 0.0171362\ttest: 0.0192719\tbest: 0.0192719 (4800)\ttotal: 11m 32s\tremaining: 28.7s\n",
      "4820:\tlearn: 0.0171209\ttest: 0.0192673\tbest: 0.0192673 (4820)\ttotal: 11m 35s\tremaining: 25.8s\n",
      "4840:\tlearn: 0.0171050\ttest: 0.0192624\tbest: 0.0192622 (4838)\ttotal: 11m 40s\tremaining: 23s\n",
      "4860:\tlearn: 0.0170894\ttest: 0.0192576\tbest: 0.0192576 (4860)\ttotal: 11m 43s\tremaining: 20.1s\n",
      "4880:\tlearn: 0.0170761\ttest: 0.0192522\tbest: 0.0192522 (4880)\ttotal: 11m 45s\tremaining: 17.2s\n",
      "4900:\tlearn: 0.0170622\ttest: 0.0192467\tbest: 0.0192467 (4900)\ttotal: 11m 47s\tremaining: 14.3s\n",
      "4920:\tlearn: 0.0170482\ttest: 0.0192436\tbest: 0.0192436 (4920)\ttotal: 11m 49s\tremaining: 11.4s\n",
      "4940:\tlearn: 0.0170354\ttest: 0.0192394\tbest: 0.0192394 (4940)\ttotal: 11m 51s\tremaining: 8.5s\n",
      "4960:\tlearn: 0.0170229\ttest: 0.0192370\tbest: 0.0192363 (4958)\ttotal: 11m 54s\tremaining: 5.62s\n",
      "4980:\tlearn: 0.0170090\ttest: 0.0192358\tbest: 0.0192353 (4978)\ttotal: 11m 56s\tremaining: 2.73s\n",
      "4999:\tlearn: 0.0169959\ttest: 0.0192339\tbest: 0.0192333 (4993)\ttotal: 12m\tremaining: 0us\n",
      "\n",
      "bestTest = 0.01923329149\n",
      "bestIteration = 4993\n",
      "\n",
      "Shrink model to first 4994 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x217e5d88a00>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)\n",
    "model = CatBoostRegressor(iterations=5000,\n",
    "                          random_seed=RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE'],\n",
    "                          silent=True,\n",
    "                          )\n",
    "model.fit(X_train, np.log(y_train),\n",
    "          cat_features=cat_features_ids,\n",
    "          eval_set=(X_test, np.log(y_test)),\n",
    "          verbose_eval=20,\n",
    "          use_best_model=True,\n",
    "          #  plot=True\n",
    "          )\n",
    "\n",
    "# model.save_model('catboost_single_model_2_baseline.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели по метрике MAPE: 28.86%\n"
     ]
    }
   ],
   "source": [
    "predict_test = np.exp(model.predict(X_test))\n",
    "predict_submission = np.exp(model.predict(X_sub))\n",
    "print(\n",
    "    f\"Точность модели по метрике MAPE: {(mape(y_test, predict_test))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.085876,
     "end_time": "2020-10-26T12:48:12.734207",
     "exception": false,
     "start_time": "2020-10-26T12:48:12.648331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:48:13.227584Z",
     "iopub.status.busy": "2020-10-26T12:48:13.226285Z",
     "iopub.status.idle": "2020-10-26T12:48:13.762529Z",
     "shell.execute_reply": "2020-10-26T12:48:13.763259Z"
    },
    "papermill": {
     "duration": 0.628302,
     "end_time": "2020-10-26T12:48:13.763488",
     "exception": false,
     "start_time": "2020-10-26T12:48:13.135186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34686 entries, 0 to 34685\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   sell_id  34686 non-null  int64  \n",
      " 1   price    34686 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 542.1 KB\n"
     ]
    }
   ],
   "source": [
    "sample_submission['price'] = predict_submission\n",
    "sample_submission.to_csv(f'submission_myds_v{VERSION}.csv', index=False)\n",
    "sample_submission.head(10)\n",
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.087712,
     "end_time": "2020-10-26T12:48:14.104388",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.016676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What's next?\n",
    "Или что еще можно сделать, чтоб улучшить результат:\n",
    "\n",
    "* Спарсить свежие данные \n",
    "* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки\n",
    "* Сгенерировать новые признаки\n",
    "* Попробовать подобрать параметры модели\n",
    "* Попробовать другие алгоритмы и библиотеки ML\n",
    "* Сделать Ансамбль моделей, Blending, Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробный чек лист: https://docs.google.com/spreadsheets/d/1I_ErM3U0Cs7Rs1obyZbIEGtVn-H47pHNCi4xdDgUmXY/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.082055,
     "end_time": "2020-10-26T12:48:14.270602",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.188547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.08168,
     "end_time": "2020-10-26T12:48:14.435554",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.353874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.080788,
     "end_time": "2020-10-26T12:48:14.596978",
     "exception": false,
     "start_time": "2020-10-26T12:48:14.51619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e3765b2726d13d924de1281d8cd6ebbe0a9052e893c0f5cda3e268a375de24e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
